# Design a URL Shortener (TinyURL)

In this part, we'll apply our systematic methodology to design a URL shortener service like TinyURL or bit.ly. This is one of the most popular system design interview questions because it covers fundamental concepts while being simple enough to design in 45 minutes.

## 1. Functional Requirements

### Actors
- **URL Creator**: Users who want to shorten long URLs
- **URL Consumer**: Users who click on shortened URLs
- **System Administrator**: Manages the service

### Use Cases

**URL Creator**:
- Create shortened URLs from long URLs
- Set custom aliases (optional)
- Set expiration dates for URLs
- View analytics (click count, geographic data)

**URL Consumer**:
- Access original URLs via shortened links
- Experience fast redirection (<100ms)

**System Administrator**:
- Monitor system health and performance
- Manage expired URLs and cleanup
- Handle abuse and spam detection

### Functional Requirements
✅ **In Scope**:
- Shorten long URLs to ~7 character format
- Redirect shortened URLs to original URLs
- Custom aliases for URLs
- URL expiration functionality
- Basic analytics (click count)
- High availability for redirections

❌ **Out of Scope**:
- User authentication/accounts
- Advanced analytics dashboard
- Real-time collaboration features
- API rate limiting (assume handled by infrastructure)

## 2. Non-Functional Requirements

### Scalability
- Support 100 million URLs shortened per month
- Handle 10 billion redirections per month
- Scale to serve global users

### Availability
- 99.9% uptime for URL creation
- 99.99% uptime for URL redirection
- Graceful degradation during failures

### Performance
- URL creation: <200ms response time
- URL redirection: <100ms response time
- Handle traffic spikes during viral content

### Data Consistency
- Strong consistency for URL creation
- Eventual consistency acceptable for analytics
- No duplicate shortened URLs

## 3. Estimations

### User Metrics
- **Daily Active Users**: 10 million
- **URLs created per day**: 3.3 million (100M/month)
- **Redirections per day**: 333 million (10B/month)

### Throughput
- **URL Creation QPS**: 38 queries/second (3.3M/24/3600)
- **URL Redirection QPS**: 3,858 queries/second (333M/24/3600)
- **Peak QPS**: 5x average = 19,290 QPS
- **Read/Write Ratio**: 100:1 (heavy read workload)

### Storage Estimations

**Per URL Storage**:
- Shortened URL: 7 bytes
- Original URL: 500 bytes (average)
- Metadata (creation date, expiration, etc.): 100 bytes
- **Total per URL**: ~600 bytes

**Storage Growth**:
- **Per Day**: 3.3M × 600 bytes = 2 GB/day
- **Per Year**: 2 GB × 365 = 730 GB/year
- **Per 5 Years**: 730 GB × 5 = 3.65 TB

### Memory Estimations

**Cache Requirements** (80/20 rule):
- 20% of URLs generate 80% of traffic
- Daily hot URLs: 333M × 20% = 66.6M URLs
- Cache size: 66.6M × 600 bytes = ~40 GB
- With replication: 40 GB × 3 = 120 GB total cache

## 4. Design Goals

### Performance Requirements
- **Latency**: <100ms for redirections, <200ms for creation
- **Throughput**: 20K QPS peak capacity
- **Consistency**: Strong for writes, eventual for analytics

### Architecture Patterns
- **Read-Heavy Workload**: Implement aggressive caching
- **Event-Driven**: Use async processing for analytics
- **Stateless Services**: Enable horizontal scaling

### Data Access Patterns
- **Random Access**: Database lookups by shortened URL key
- **Write Once, Read Many**: URLs rarely modified after creation
- **Cache-Friendly**: High cache hit ratios expected

## 5. High-Level Design

### Building Blocks

```
[Client] → [Load Balancer] → [Web Servers] → [Cache] → [Database]
                                    ↓
                            [Analytics Service] → [Analytics DB]
                                    ↓
                              [Message Queue]
```

### Core Components

1. **Load Balancer**: Distributes traffic across web servers
2. **Web Servers**: Handle URL creation and redirection logic
3. **Cache Layer**: Redis cluster for hot URL lookups
4. **Database**: Primary storage for URL mappings
5. **Analytics Service**: Processes click events asynchronously
6. **Message Queue**: Decouples analytics from main flow

### API Design

**Create Short URL**:
```http
POST /api/v1/shorten
Content-Type: application/json

{
  "long_url": "https://example.com/very/long/path",
  "custom_alias": "mylink", // optional
  "expiration_date": "2024-12-31" // optional
}

Response:
{
  "short_url": "https://short.ly/abc123",
  "long_url": "https://example.com/very/long/path",
  "created_at": "2024-06-17T10:00:00Z",
  "expires_at": "2024-12-31T23:59:59Z"
}
```

**Redirect URL**:
```http
GET /{short_code}

Response: 301 Redirect
Location: https://example.com/very/long/path
```

**Get Analytics**:
```http
GET /api/v1/analytics/{short_code}

Response:
{
  "short_code": "abc123",
  "click_count": 1542,
  "created_at": "2024-06-17T10:00:00Z",
  "last_accessed": "2024-06-17T15:30:00Z"
}
```

### Data Schema

**URLs Table**:
```sql
CREATE TABLE urls (
    short_code VARCHAR(7) PRIMARY KEY,
    long_url TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    expires_at TIMESTAMP,
    click_count BIGINT DEFAULT 0,
    created_by_ip VARCHAR(45)
);

CREATE INDEX idx_expires_at ON urls(expires_at);
```

**Analytics Events Table**:
```sql
CREATE TABLE click_events (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    short_code VARCHAR(7) NOT NULL,
    clicked_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    user_ip VARCHAR(45),
    user_agent TEXT,
    referer TEXT
);

CREATE INDEX idx_short_code_time ON click_events(short_code, clicked_at);
```

## URL Encoding Algorithm

### Base62 Encoding

We'll use Base62 encoding (a-z, A-Z, 0-9) to generate short codes:

```python
def base62_encode(num):
    base = 62
    alphabet = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"
    encoded = ""
    
    while num > 0:
        encoded = alphabet[num % base] + encoded
        num //= base
    
    return encoded or alphabet[0]

def base62_decode(encoded):
    base = 62
    alphabet = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"
    num = 0
    
    for char in encoded:
        num = num * base + alphabet.index(char)
    
    return num
```

### Counter-Based Approach

1. Use auto-incrementing database counter
2. Encode counter value to Base62
3. With 7 characters: 62^7 = 3.5 trillion possible URLs

**Advantages**:
- No collisions
- Predictable, sequential generation
- Simple implementation

**Disadvantages**:
- Sequential patterns might be guessable
- Single point of failure for counter

### Alternative: Hash-Based Approach

```python
import hashlib

def generate_short_code(long_url, timestamp):
    data = f"{long_url}{timestamp}"
    hash_value = hashlib.md5(data.encode()).hexdigest()
    
    # Take first 7 characters and convert to Base62
    return hash_value[:7]
```

## Detailed Design Deep Dive

### Caching Strategy

**Multi-Layer Caching**:

1. **Browser Cache**: Cache 301 redirects for 1 hour
2. **CDN Cache**: Cache popular URLs at edge locations
3. **Application Cache**: Redis cluster with:
   - TTL: 24 hours for hot URLs
   - LRU eviction policy
   - 99% hit ratio target

**Cache Key Strategy**:
```
Key: "url:{short_code}"
Value: {
  "long_url": "https://example.com/path",
  "expires_at": "2024-12-31T23:59:59Z"
}
```

### Database Sharding

**Shard by Short Code**:
- Consistent hashing on short_code
- 4 shards initially, plan for 16 shards
- Each shard handles ~25% of traffic

**Shard Key**: First 2 characters of short_code
- Shard 1: aa-pz
- Shard 2: qa-9z  
- Shard 3: Aa-Pz
- Shard 4: Qa-9z

### Analytics Processing

**Async Event Processing**:
1. URL click triggers event
2. Event published to message queue
3. Analytics service processes events in batches
4. Updates click counts every 5 minutes

**Analytics Pipeline**:
```
[Click Event] → [Kafka Queue] → [Analytics Worker] → [Analytics DB]
                                        ↓
                                [Real-time Dashboard]
```

## Scaling Considerations

### Handling Traffic Spikes

**Auto-Scaling Strategy**:
- Monitor QPS and response time
- Scale web servers horizontally
- Pre-warm cache for viral content
- Circuit breakers for graceful degradation

### Geographic Distribution

**Multi-Region Deployment**:
- Primary region: US-East (main database)
- Secondary regions: EU-West, Asia-Pacific
- Read replicas in each region
- Global load balancer routes to nearest region

### Performance Optimizations

1. **Connection Pooling**: Reuse database connections
2. **Async Processing**: Non-blocking I/O for analytics
3. **Batch Operations**: Group database writes
4. **CDN Integration**: Cache static assets and popular URLs

## Security Considerations

### Spam Prevention
- Rate limiting per IP address
- URL validation and sanitization
- Malicious URL detection
- CAPTCHA for suspicious traffic

### Data Protection
- HTTPS enforcement
- SQL injection prevention
- Input validation for custom aliases
- Access logs for audit trails

## URL Shortener Design Quiz

Test your understanding of URL shortener system design with the interactive quiz that appears after each part of this series.

## Key Takeaways

1. **Read-Heavy Optimization**: Aggressive caching is crucial for URL shorteners
2. **Simple but Scalable**: Start simple, add complexity as needed
3. **Analytics Separation**: Decouple analytics from core functionality
4. **Global Distribution**: CDNs and regional deployments improve performance
5. **Failure Planning**: Design for graceful degradation during traffic spikes

## What's Next?

In Part 3, we'll design a real-time chat system like WhatsApp, which introduces new challenges around WebSocket connections, message delivery guarantees, and online presence management.
