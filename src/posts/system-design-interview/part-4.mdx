# Design a Social Media Feed (Twitter)

In this part, we'll design a social media feed system like Twitter. This problem introduces complex challenges around content ranking, timeline generation, viral content handling, and personalized content delivery.

## 1. Functional Requirements

### Actors
- **User**: Posts and consumes content
- **Content Creator**: Influential users with many followers
- **Content Moderator**: Reviews flagged content
- **System**: Manages recommendations and trending

### Use Cases

**User**:
- Post tweets (text, images, videos)
- Follow/unfollow other users
- View personalized timeline
- Like, retweet, and comment on posts
- Search for tweets and users
- View trending topics

**Content Creator**:
- Publish content to large audiences
- View analytics and engagement metrics
- Promote content

**Content Moderator**:
- Review reported content
- Take action on policy violations

### Functional Requirements
✅ **In Scope**:
- Post tweets (280 characters, media support)
- Follow/unfollow users
- Home timeline (personalized feed)
- User timeline (user's own tweets)
- Like, retweet, reply functionality
- Trending topics and hashtags
- Search functionality
- Basic analytics

❌ **Out of Scope**:
- Direct messaging (covered in Part 3)
- Live streaming
- Advanced recommendation algorithms
- Advertisement system
- Advanced analytics dashboard

## 2. Non-Functional Requirements

### Scalability
- Support 500 million users
- Handle 300 million tweets per day
- Support 100 million daily active users
- Handle traffic spikes during viral events

### Availability
- 99.9% uptime for timeline generation
- 99.99% uptime for tweet reading
- Graceful degradation during peak traffic

### Performance
- Timeline generation: &lt;200ms
- Tweet posting: &lt;100ms
- Search results: &lt;300ms
- Handle 300K tweets/second during peak

### Data Consistency
- Eventual consistency for timeline updates
- Strong consistency for user actions (follow/unfollow)
- Tweet immutability after posting

## 3. Estimations

### User Metrics
- **Total Users**: 500 million
- **Daily Active Users**: 100 million
- **Average tweets per user per day**: 3
- **Average follows per user**: 200
- **Heavy users (celebrities)**: 1% with 1M+ followers

### Tweet Volume
- **Tweets per day**: 300 million
- **Tweets per second**: 3,472 average
- **Peak TPS**: 17,360 (5x average)
- **Tweet fanout ratio**: 1:200 (average followers)

### Storage Estimations

**Per Tweet Storage**:
- Tweet ID: 8 bytes
- User ID: 8 bytes
- Content: 300 bytes (average with metadata)
- Media URLs: 100 bytes
- Timestamps: 16 bytes
- **Total per tweet**: ~450 bytes

**Storage Growth**:
- **Per Day**: 300M × 450 bytes = 135 GB/day
- **Per Year**: 135 GB × 365 = 49 TB/year
- **Per 5 Years**: 245 TB

**Timeline Cache Storage**:
- Cache top 1000 tweets per user
- 100M users × 1000 tweets × 450 bytes = 45 TB cache

## 4. Design Goals

### Performance Requirements
- **Timeline Generation**: &lt;200ms for cached timelines
- **Tweet Publishing**: &lt;100ms response time
- **Search**: &lt;300ms for result delivery
- **Viral Content**: Handle 100K retweets/minute

### Architecture Patterns
- **Event-Driven**: Tweet fanout and timeline updates
- **CQRS**: Separate read and write models
- **Cache-Heavy**: Aggressive caching for read performance

### Usage Patterns
- **Read Heavy**: 300:1 read to write ratio
- **Real-time**: Immediate timeline updates
- **Spike Traffic**: Viral content creates traffic spikes

## 5. High-Level Design

### Building Blocks

```
[Client] → [Load Balancer] → [API Gateway] → [Tweet Service]
                                    ↓           ↓
                            [Timeline Service] [User Service]
                                    ↓           ↓
                            [Fanout Service] → [Cache Layer]
                                    ↓           ↓
                            [Message Queue] → [Database Cluster]
                                    ↓           ↓
                            [Search Service] [Media Service]
```

### Core Components

1. **API Gateway**: Routes requests and handles authentication
2. **Tweet Service**: Handles tweet creation and retrieval
3. **Timeline Service**: Generates and serves user timelines
4. **Fanout Service**: Distributes tweets to followers
5. **User Service**: Manages user profiles and relationships
6. **Search Service**: Provides tweet and user search
7. **Cache Layer**: Multi-tier caching for performance

### API Design

**Post Tweet**:
```http
POST /api/v1/tweets
Authorization: Bearer {token}
{
  "content": "Hello world! #myFirstTweet",
  "media_urls": ["https://cdn.example.com/image1.jpg"],
  "reply_to": null
}

Response:
{
  "tweet_id": "1234567890",
  "user_id": "user_123",
  "content": "Hello world! #myFirstTweet",
  "created_at": "2024-06-17T10:00:00Z",
  "engagement": {
    "likes": 0,
    "retweets": 0,
    "replies": 0
  }
}
```

**Get Timeline**:
```http
GET /api/v1/timeline?type=home&limit=20&cursor=tweet_123

Response:
{
  "tweets": [
    {
      "tweet_id": "1234567890",
      "user": {
        "user_id": "user_456",
        "username": "@johndoe",
        "display_name": "John Doe",
        "avatar_url": "https://cdn.example.com/avatar.jpg"
      },
      "content": "Great weather today!",
      "created_at": "2024-06-17T10:00:00Z",
      "engagement": {
        "likes": 42,
        "retweets": 15,
        "replies": 8
      },
      "media": []
    }
  ],
  "next_cursor": "tweet_456",
  "has_more": true
}
```

**Follow User**:
```http
POST /api/v1/users/{user_id}/follow

Response:
{
  "following": true,
  "follower_count": 1543,
  "following_count": 287
}
```

### Database Schema

**Users Table**:
```sql
CREATE TABLE users (
    user_id BIGINT PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    display_name VARCHAR(100),
    bio TEXT,
    avatar_url VARCHAR(500),
    verified BOOLEAN DEFAULT FALSE,
    follower_count INT DEFAULT 0,
    following_count INT DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Tweets Table** (Partitioned by created_at):
```sql
CREATE TABLE tweets (
    tweet_id BIGINT PRIMARY KEY,
    user_id BIGINT NOT NULL,
    content TEXT NOT NULL,
    reply_to BIGINT,
    retweet_of BIGINT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    like_count INT DEFAULT 0,
    retweet_count INT DEFAULT 0,
    reply_count INT DEFAULT 0,
    
    INDEX idx_user_time (user_id, created_at),
    INDEX idx_reply_to (reply_to),
    FOREIGN KEY (user_id) REFERENCES users(user_id)
) PARTITION BY RANGE (UNIX_TIMESTAMP(created_at));
```

**Follows Table** (Sharded by follower_id):
```sql
CREATE TABLE follows (
    follower_id BIGINT,
    following_id BIGINT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    PRIMARY KEY (follower_id, following_id),
    INDEX idx_following (following_id, follower_id)
);
```

**Timeline Cache Table**:
```sql
CREATE TABLE user_timelines (
    user_id BIGINT,
    tweet_id BIGINT,
    score DECIMAL(10,2), -- for ranking
    created_at TIMESTAMP,
    
    PRIMARY KEY (user_id, score, tweet_id),
    INDEX idx_user_time (user_id, created_at)
);
```

## Timeline Generation Strategies

### Push Model (Write-Heavy)

**Tweet Fanout on Write**:
```python
class PushTimelineService:
    def fanout_tweet(self, tweet, user_id):
        # Get all followers
        followers = self.user_service.get_followers(user_id)
        
        # Add tweet to each follower's timeline
        for follower_id in followers:
            self.timeline_cache.add_to_timeline(follower_id, tweet)
            
            # Limit timeline size (keep only latest 1000 tweets)
            self.timeline_cache.trim_timeline(follower_id, max_size=1000)
    
    def get_timeline(self, user_id, limit=20):
        # Timeline is pre-computed, just read from cache
        return self.timeline_cache.get_timeline(user_id, limit)
```

**Advantages**:
- Fast timeline reads (pre-computed)
- Real-time timeline updates
- Simple implementation

**Disadvantages**:
- Expensive for users with many followers
- Storage overhead (duplicate tweets)
- Celebrity problem (1M+ followers)

### Pull Model (Read-Heavy)

**Timeline Generation on Read**:
```python
class PullTimelineService:
    def get_timeline(self, user_id, limit=20):
        # Get users that this user follows
        following = self.user_service.get_following(user_id)
        
        # Get recent tweets from each followed user
        all_tweets = []
        for followed_user_id in following:
            tweets = self.tweet_service.get_user_tweets(
                followed_user_id, 
                limit=100
            )
            all_tweets.extend(tweets)
        
        # Sort by timestamp and return top tweets
        sorted_tweets = sorted(all_tweets, key=lambda x: x.created_at, reverse=True)
        return sorted_tweets[:limit]
```

**Advantages**:
- No fanout cost for popular users
- No storage duplication
- Consistent view of latest data

**Disadvantages**:
- Slow timeline generation
- Database load on read
- Difficult to rank by engagement

### Hybrid Model (Recommended)

**Smart Fanout Strategy**:
```python
class HybridTimelineService:
    def __init__(self):
        self.celebrity_threshold = 1000000  # 1M followers
        
    def fanout_tweet(self, tweet, user_id):
        follower_count = self.user_service.get_follower_count(user_id)
        
        if follower_count > self.celebrity_threshold:
            # Celebrity: don't fanout, use pull on read
            self.celebrity_tweets_cache.add(user_id, tweet)
        else:
            # Regular user: fanout to all followers
            followers = self.user_service.get_followers(user_id)
            for follower_id in followers:
                self.timeline_cache.add_to_timeline(follower_id, tweet)
    
    def get_timeline(self, user_id, limit=20):
        # Get pre-computed timeline
        timeline_tweets = self.timeline_cache.get_timeline(user_id, limit)
        
        # Get tweets from celebrities this user follows
        celebrity_following = self.user_service.get_celebrity_following(user_id)
        celebrity_tweets = []
        
        for celebrity_id in celebrity_following:
            tweets = self.celebrity_tweets_cache.get_recent_tweets(celebrity_id, 10)
            celebrity_tweets.extend(tweets)
        
        # Merge and sort all tweets
        all_tweets = timeline_tweets + celebrity_tweets
        sorted_tweets = sorted(all_tweets, key=lambda x: x.created_at, reverse=True)
        
        return sorted_tweets[:limit]
```

## Detailed Design Deep Dive

### Fanout Service Architecture

**Async Fanout Processing**:
```python
class FanoutService:
    def __init__(self):
        self.message_queue = MessageQueue()
        self.batch_size = 1000
        
    def queue_fanout(self, tweet):
        # Queue fanout job for async processing
        fanout_job = {
            "tweet_id": tweet.id,
            "user_id": tweet.user_id,
            "timestamp": tweet.created_at
        }
        self.message_queue.publish("fanout_queue", fanout_job)
    
    def process_fanout_batch(self, jobs):
        # Process multiple fanout jobs in batch
        for job in jobs:
            followers = self.get_followers_batch(job.user_id)
            
            # Batch insert into timeline cache
            timeline_entries = []
            for follower_id in followers:
                timeline_entries.append({
                    "user_id": follower_id,
                    "tweet_id": job.tweet_id,
                    "score": self.calculate_score(job),
                    "created_at": job.timestamp
                })
            
            self.timeline_cache.batch_insert(timeline_entries)
```

### Caching Strategy

**Multi-Layer Cache Architecture**:

1. **L1 Cache**: Application-level cache (Recent timelines)
2. **L2 Cache**: Redis cluster (User timelines, tweet data)
3. **L3 Cache**: CDN (Media files, static content)

```python
class CacheManager:
    def __init__(self):
        self.l1_cache = LRUCache(max_size=10000)  # In-memory
        self.l2_cache = RedisCluster()
        self.l3_cache = CDN()
    
    def get_timeline(self, user_id, limit=20):
        cache_key = f"timeline:{user_id}:{limit}"
        
        # Try L1 cache first
        timeline = self.l1_cache.get(cache_key)
        if timeline:
            return timeline
            
        # Try L2 cache (Redis)
        timeline = self.l2_cache.get(cache_key)
        if timeline:
            self.l1_cache.set(cache_key, timeline, ttl=60)
            return timeline
            
        # Generate timeline and cache
        timeline = self.timeline_service.generate_timeline(user_id, limit)
        
        self.l2_cache.set(cache_key, timeline, ttl=300)
        self.l1_cache.set(cache_key, timeline, ttl=60)
        
        return timeline
```

### Search Service

**Elasticsearch Integration**:
```python
class SearchService:
    def __init__(self):
        self.elasticsearch = Elasticsearch()
        
    def index_tweet(self, tweet):
        doc = {
            "tweet_id": tweet.id,
            "user_id": tweet.user_id,
            "username": tweet.user.username,
            "content": tweet.content,
            "hashtags": self.extract_hashtags(tweet.content),
            "mentions": self.extract_mentions(tweet.content),
            "created_at": tweet.created_at,
            "engagement_score": self.calculate_engagement_score(tweet)
        }
        
        self.elasticsearch.index(
            index="tweets",
            id=tweet.id,
            body=doc
        )
    
    def search_tweets(self, query, limit=20, offset=0):
        search_body = {
            "query": {
                "bool": {
                    "should": [
                        {"match": {"content": {"query": query, "boost": 2}}},
                        {"match": {"hashtags": {"query": query, "boost": 3}}},
                        {"match": {"username": {"query": query, "boost": 1.5}}}
                    ]
                }
            },
            "sort": [
                {"engagement_score": {"order": "desc"}},
                {"created_at": {"order": "desc"}}
            ],
            "size": limit,
            "from": offset
        }
        
        return self.elasticsearch.search(index="tweets", body=search_body)
```

### Trending Topics

**Real-time Trend Detection**:
```python
class TrendingService:
    def __init__(self):
        self.redis = Redis()
        self.trend_window = 3600  # 1 hour window
        
    def update_hashtag_count(self, hashtag):
        current_hour = int(time.time() // self.trend_window)
        key = f"hashtag_count:{current_hour}:{hashtag}"
        
        # Increment count for current hour
        self.redis.incr(key)
        self.redis.expire(key, self.trend_window * 2)  # Keep 2 hours
        
        # Update global trending scores
        self.update_trending_score(hashtag)
    
    def get_trending_topics(self, limit=10):
        # Get top hashtags by score
        return self.redis.zrevrange("trending_hashtags", 0, limit-1, withscores=True)
    
    def calculate_trend_score(self, hashtag, current_count, historical_avg):
        # Simple trending algorithm
        if historical_avg == 0:
            return current_count
        
        trend_ratio = current_count / historical_avg
        velocity_score = trend_ratio * math.log(current_count + 1)
        
        return velocity_score
```

## Scaling Considerations

### Database Sharding

**Tweets Sharding Strategy**:
```python
def get_tweet_shard(tweet_id):
    # Shard by tweet_id for even distribution
    return tweet_id % NUM_TWEET_SHARDS

def get_user_shard(user_id):
    # Shard by user_id for user-related data
    return user_id % NUM_USER_SHARDS
```

**Timeline Sharding**:
```python
def get_timeline_shard(user_id):
    # Shard user timelines by user_id
    return user_id % NUM_TIMELINE_SHARDS
```

### Handling Viral Content

**Circuit Breaker for Fanout**:
```python
class ViralContentHandler:
    def __init__(self):
        self.fanout_threshold = 100000  # 100K followers
        self.circuit_breaker = CircuitBreaker()
        
    def handle_viral_tweet(self, tweet, user_id):
        follower_count = self.user_service.get_follower_count(user_id)
        
        if follower_count > self.fanout_threshold:
            # Skip immediate fanout for viral content
            self.queue_delayed_fanout(tweet, delay=60)  # 1 minute delay
            
            # Use pull model for immediate reads
            self.celebrity_cache.add_hot_tweet(user_id, tweet)
        else:
            # Normal fanout
            self.fanout_service.fanout_tweet(tweet, user_id)
```

### Media Handling

**CDN Strategy for Media**:
```python
class MediaService:
    def __init__(self):
        self.cdn = CloudFrontCDN()
        self.storage = S3Storage()
        
    def upload_media(self, media_file, user_id):
        # Generate unique filename
        filename = f"{user_id}/{uuid.uuid4()}.{media_file.extension}"
        
        # Upload to S3
        s3_url = self.storage.upload(filename, media_file)
        
        # Generate CDN URL
        cdn_url = self.cdn.get_url(filename)
        
        return {
            "media_id": str(uuid.uuid4()),
            "original_url": s3_url,
            "cdn_url": cdn_url,
            "thumbnail_url": self.generate_thumbnail(cdn_url)
        }
```

## Social Media Feed Design Quiz

Test your understanding of social media feed system design with the interactive quiz that appears after each part of this series.

## Key Takeaways

1. **Hybrid Approach**: Combine push and pull models based on user characteristics
2. **Aggressive Caching**: Multi-layer caching is essential for read performance
3. **Async Processing**: Use message queues for fanout and background processing
4. **Viral Content**: Design circuit breakers and fallback mechanisms
5. **Search Integration**: Elasticsearch enables fast, relevant search results

## What's Next?

In Part 5, we'll design a video streaming service like YouTube, which introduces challenges around large file storage, content delivery networks, and video processing pipelines.
