export const metadata = {
  title: "Agentic AI & Multi-Agent Systems",
  date: "2024-12-01",
  excerpt: "Explore Agentic AI - the next frontier in artificial intelligence. Learn about autonomous agents that can plan, execute, and coordinate to solve complex tasks.",
  author: "Abstract Algorithms",
  tags: ["agentic-ai", "multi-agent-systems", "autonomous-agents", "ai-planning", "agent-coordination", "goal-oriented-ai"],
  coverImage: "./assets/part-9.png",
  series: {
    name: "GenAI Mastery",
    order: 9,
    total: 12,
    prev: "/posts/genai-mastery-series/part-8",
    next: "/posts/genai-mastery-series/part-10"
  }
}

# Agentic AI & Multi-Agent Systems

Agentic AI represents the next frontier in artificial intelligence - systems that can autonomously plan, execute, and adapt to achieve goals. Unlike traditional AI that responds to prompts, agents can reason about problems, use tools, and coordinate with other agents to solve complex tasks.

![Agentic AI Overview](../assets/agentic-ai-overview.png)
*Evolution from reactive AI to autonomous agents*

## üéØ Learning Objectives

By the end of this part, you will:
- Understand agent architectures and design patterns
- Master tool integration and function calling
- Build autonomous agents that can plan and execute
- Design multi-agent systems with coordination
- Implement real-world agentic AI applications

## üìö Table of Contents

1. [What Makes AI "Agentic"](#what-is-agentic)
2. [Agent Architectures & Frameworks](#architectures)
3. [Tool Use & Function Calling](#tools)
4. [Planning & Reasoning](#planning)
5. [Memory & State Management](#memory)
6. [Multi-Agent Coordination](#multi-agent)
7. [Real-World Agent Applications](#applications)
8. [Building Production Agents](#production)
9. [Agent Safety & Control](#safety)
10. [Hands-on Project](#project)

---

## ü§ñ What Makes AI "Agentic"

Traditional AI systems are reactive - they respond to inputs with outputs. Agentic AI systems are proactive - they can set goals, make plans, and take actions to achieve objectives.

![Reactive vs Agentic AI](../assets/reactive-vs-agentic.png)
*Key differences between traditional and agentic AI*

### Characteristics of Agentic AI

**üéØ Goal-Oriented**: Agents work toward specific objectives
**üìã Planning**: Can break down complex tasks into steps
**üîß Tool Use**: Can interact with external systems and APIs
**üß† Reasoning**: Makes decisions based on current state and goals
**üîÑ Adaptation**: Learns from feedback and adjusts approach
**ü§ù Collaboration**: Can work with other agents and humans

### Agent Components

![Agent Architecture](../assets/agent-components.png)
*Core components of an intelligent agent*

**Brain (LLM)**: The reasoning and decision-making core
**Memory**: Short-term and long-term information storage
**Tools**: External capabilities the agent can invoke
**Planning**: Strategy for achieving goals
**Execution**: Action-taking and monitoring
**Communication**: Interface with users and other agents

### Types of Agents

**1. Reactive Agents**
- Respond to immediate stimuli
- No internal state or planning
- Example: Simple chatbots

**2. Deliberative Agents**
- Maintain internal state
- Plan before acting
- Example: Task automation agents

**3. Learning Agents**
- Improve performance over time
- Adapt strategies based on experience
- Example: Personalized assistants

**4. Social Agents**
- Communicate and coordinate with others
- Understand social contexts
- Example: Collaborative research agents

---

## üèóÔ∏è Agent Architectures & Frameworks

Different agent architectures serve different purposes. Let's explore the major patterns and frameworks.

![Agent Architectures](../assets/agent-architectures.png)
*Popular agent architecture patterns*

### 1. ReAct (Reasoning + Acting)

Combines reasoning and acting in an interleaved manner.

```python
class ReActAgent:
    def __init__(self, llm, tools):
        self.llm = llm
        self.tools = tools
    
    def solve(self, task):
        thought = ""
        for step in range(max_steps):
            # Reasoning step
            prompt = f"""
            Task: {task}
            Previous thoughts: {thought}
            
            Think about what to do next. You can:
            1. Think about the problem
            2. Use a tool: {list(self.tools.keys())}
            3. Give a final answer
            
            Thought:"""
            
            response = self.llm.generate(prompt)
            
            if "Final Answer:" in response:
                return response.split("Final Answer:")[1].strip()
            elif "Action:" in response:
                action = self.parse_action(response)
                result = self.execute_action(action)
                thought += f"\nAction: {action}\nResult: {result}"
            else:
                thought += f"\nThought: {response}"
```

### 2. Plan-and-Execute

Separates planning from execution for complex tasks.

```python
class PlanAndExecuteAgent:
    def __init__(self, planner_llm, executor_llm, tools):
        self.planner = planner_llm
        self.executor = executor_llm
        self.tools = tools
    
    def solve(self, task):
        # Planning phase
        plan = self.create_plan(task)
        
        # Execution phase
        results = []
        for step in plan.steps:
            result = self.execute_step(step)
            results.append(result)
            
            # Re-plan if necessary
            if result.requires_replanning:
                plan = self.replan(task, results, remaining_steps)
        
        return self.synthesize_results(task, results)
    
    def create_plan(self, task):
        prompt = f"""
        Create a detailed plan to accomplish this task: {task}
        
        Available tools: {list(self.tools.keys())}
        
        Break down the task into specific, actionable steps.
        Each step should be clear and executable.
        
        Plan:"""
        
        plan_text = self.planner.generate(prompt)
        return self.parse_plan(plan_text)
```

### 3. Reflexion

Agents that can reflect on and improve their performance.

```python
class ReflexionAgent:
    def __init__(self, llm, tools, memory):
        self.llm = llm
        self.tools = tools
        self.memory = memory
    
    def solve_with_reflection(self, task, max_attempts=3):
        for attempt in range(max_attempts):
            # Attempt to solve
            solution = self.attempt_solution(task)
            
            # Evaluate solution
            evaluation = self.evaluate_solution(task, solution)
            
            if evaluation.is_satisfactory:
                return solution
            
            # Reflect on failure
            reflection = self.reflect_on_failure(
                task, solution, evaluation
            )
            
            # Store learning for next attempt
            self.memory.store_reflection(task, reflection)
        
        return self.best_attempt
    
    def reflect_on_failure(self, task, solution, evaluation):
        prompt = f"""
        Task: {task}
        Attempted solution: {solution}
        Issues found: {evaluation.issues}
        
        Reflect on what went wrong and how to improve:
        1. What assumptions were incorrect?
        2. What information was missing?
        3. What different approach should be tried?
        
        Reflection:"""
        
        return self.llm.generate(prompt)
```

### Popular Agent Frameworks

**LangChain Agents**
```python
from langchain.agents import create_openai_functions_agent
from langchain.tools import DuckDuckGoSearchRun

# Define tools
search = DuckDuckGoSearchRun()
tools = [search]

# Create agent
agent = create_openai_functions_agent(
    llm=llm,
    tools=tools,
    prompt=agent_prompt
)

# Execute
agent_executor = AgentExecutor(
    agent=agent, 
    tools=tools, 
    verbose=True
)

result = agent_executor.invoke({"input": "Research latest AI trends"})
```

**AutoGPT Pattern**
```python
class AutoGPTAgent:
    def __init__(self, name, role, goals, llm, tools):
        self.name = name
        self.role = role
        self.goals = goals
        self.llm = llm
        self.tools = tools
        self.memory = []
    
    def autonomous_loop(self):
        while not self.goals_achieved():
            # Assess current situation
            situation = self.assess_situation()
            
            # Choose next action
            action = self.choose_action(situation)
            
            # Execute action
            result = self.execute_action(action)
            
            # Update memory
            self.memory.append({
                'situation': situation,
                'action': action,
                'result': result
            })
            
            # Reflect and adjust goals if needed
            self.reflect_and_adjust()
```

---

## üîß Tool Use & Function Calling

The ability to use external tools dramatically expands agent capabilities. Modern agents can call APIs, run code, search the web, and interact with databases.

![Tool Integration](../assets/tool-integration.png)
*How agents integrate with external tools and services*

### Function Calling with OpenAI

OpenAI's function calling allows agents to use structured tools.

```python
import openai
import json

# Define tool schema
tools = [
    {
        "type": "function",
        "function": {
            "name": "search_web",
            "description": "Search the web for information",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Search query"
                    }
                },
                "required": ["query"]
            }
        }
    },
    {
        "type": "function", 
        "function": {
            "name": "calculate",
            "description": "Perform mathematical calculations",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "Mathematical expression to evaluate"
                    }
                },
                "required": ["expression"]
            }
        }
    }
]

def call_agent_with_tools(message):
    response = openai.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": message}],
        tools=tools,
        tool_choice="auto"
    )
    
    message = response.choices[0].message
    
    if message.tool_calls:
        for tool_call in message.tool_calls:
            function_name = tool_call.function.name
            arguments = json.loads(tool_call.function.arguments)
            
            # Execute the function
            if function_name == "search_web":
                result = search_web(arguments["query"])
            elif function_name == "calculate":
                result = calculate(arguments["expression"])
            
            # Continue conversation with result
            # ... (add result to conversation)
    
    return response
```

### Building Custom Tools

```python
from typing import Any, Dict
from pydantic import BaseModel

class ToolSchema(BaseModel):
    name: str
    description: str
    parameters: Dict[str, Any]

class BaseTool:
    schema: ToolSchema
    
    def execute(self, **kwargs) -> str:
        raise NotImplementedError

class WebSearchTool(BaseTool):
    schema = ToolSchema(
        name="web_search",
        description="Search the web for current information",
        parameters={
            "type": "object",
            "properties": {
                "query": {"type": "string"},
                "num_results": {"type": "integer", "default": 5}
            },
            "required": ["query"]
        }
    )
    
    def execute(self, query: str, num_results: int = 5) -> str:
        # Implement actual web search
        results = search_engine.search(query, limit=num_results)
        return f"Search results for '{query}':\n" + \
               "\n".join([f"- {r.title}: {r.snippet}" for r in results])

class CodeExecutorTool(BaseTool):
    schema = ToolSchema(
        name="execute_code",
        description="Execute Python code in a sandboxed environment",
        parameters={
            "type": "object",
            "properties": {
                "code": {"type": "string"},
                "language": {"type": "string", "default": "python"}
            },
            "required": ["code"]
        }
    )
    
    def execute(self, code: str, language: str = "python") -> str:
        if language == "python":
            try:
                # Use restricted execution environment
                result = exec_python_safely(code)
                return f"Code executed successfully:\n{result}"
            except Exception as e:
                return f"Code execution failed: {e}"
        else:
            return f"Language {language} not supported"
```

### Tool Composition and Chaining

```python
class ToolChain:
    def __init__(self, tools):
        self.tools = {tool.schema.name: tool for tool in tools}
    
    def execute_chain(self, agent_plan):
        results = {}
        
        for step in agent_plan.steps:
            tool_name = step.tool
            parameters = step.parameters
            
            if tool_name in self.tools:
                result = self.tools[tool_name].execute(**parameters)
                results[step.id] = result
                
                # Pass result to next step if needed
                if hasattr(step, 'output_to'):
                    for next_step_id in step.output_to:
                        next_step = agent_plan.get_step(next_step_id)
                        next_step.add_context(result)
        
        return results

# Example: Research agent with tool chaining
research_plan = AgentPlan([
    Step(id="search", tool="web_search", 
         parameters={"query": "latest AI developments 2024"}),
    Step(id="summarize", tool="text_summarizer",
         parameters={"text": "{{search.result}}"}, 
         depends_on=["search"]),
    Step(id="format", tool="markdown_formatter",
         parameters={"content": "{{summarize.result}}"},
         depends_on=["summarize"])
])
```

---

## üß† Planning & Reasoning

Sophisticated agents need to plan multi-step solutions and reason about complex problems.

![Planning Strategies](../assets/planning-strategies.png)
*Different approaches to agent planning*

### Planning Algorithms

**1. Forward Planning**
Start from current state, work toward goal.

```python
class ForwardPlanner:
    def __init__(self, world_model, goal_checker):
        self.world_model = world_model
        self.goal_checker = goal_checker
    
    def plan(self, initial_state, goal):
        frontier = [PlanNode(state=initial_state, actions=[])]
        visited = set()
        
        while frontier:
            current_node = frontier.pop(0)
            
            if self.goal_checker.is_satisfied(current_node.state, goal):
                return current_node.actions
            
            if current_node.state in visited:
                continue
            visited.add(current_node.state)
            
            # Generate possible next actions
            for action in self.get_valid_actions(current_node.state):
                new_state = self.world_model.predict_state(
                    current_node.state, action
                )
                new_actions = current_node.actions + [action]
                frontier.append(PlanNode(new_state, new_actions))
        
        return None  # No plan found
```

**2. Hierarchical Planning**
Break complex goals into subgoals.

```python
class HierarchicalPlanner:
    def __init__(self, llm, task_decomposer):
        self.llm = llm
        self.task_decomposer = task_decomposer
    
    def plan(self, complex_goal):
        # Decompose into subgoals
        subgoals = self.task_decomposer.decompose(complex_goal)
        
        plan = Plan()
        for subgoal in subgoals:
            if self.is_primitive(subgoal):
                # Direct action
                action = self.create_action(subgoal)
                plan.add_action(action)
            else:
                # Recursive planning
                subplan = self.plan(subgoal)
                plan.add_subplan(subplan)
        
        return plan
    
    def decompose_with_llm(self, goal):
        prompt = f"""
        Break down this complex goal into smaller, manageable subgoals:
        
        Goal: {goal}
        
        Consider:
        1. What are the prerequisite steps?
        2. What can be done in parallel?
        3. What dependencies exist between steps?
        
        Subgoals:"""
        
        response = self.llm.generate(prompt)
        return self.parse_subgoals(response)
```

**3. Reactive Planning**
Adapt plans based on changing conditions.

```python
class ReactivePlanner:
    def __init__(self, base_planner, monitor):
        self.base_planner = base_planner
        self.monitor = monitor
    
    def execute_with_adaptation(self, goal):
        plan = self.base_planner.plan(goal)
        
        for action in plan.actions:
            # Check if conditions still hold
            if not self.monitor.conditions_valid(action):
                # Replan from current state
                remaining_goal = self.update_goal(goal, completed_actions)
                new_plan = self.base_planner.plan(remaining_goal)
                plan = Plan(completed_actions + new_plan.actions)
            
            # Execute action
            result = self.execute_action(action)
            completed_actions.append(action)
            
            # Monitor for unexpected outcomes
            if self.monitor.unexpected_outcome(result):
                self.handle_unexpected_outcome(result)
```

### Advanced Reasoning Techniques

**Chain-of-Thought Planning**
```python
def chain_of_thought_planning(goal, llm):
    prompt = f"""
    Goal: {goal}
    
    Let's think through this step by step:
    
    1. What do I need to understand about this problem?
    2. What information do I need to gather?
    3. What are the key challenges?
    4. What's the logical sequence of actions?
    5. How will I know if I'm successful?
    
    Thinking process:"""
    
    reasoning = llm.generate(prompt)
    
    # Extract plan from reasoning
    plan_prompt = f"""
    Based on this reasoning: {reasoning}
    
    Create a concrete action plan:"""
    
    plan = llm.generate(plan_prompt)
    return parse_action_plan(plan)
```

**Tree of Thoughts**
```python
class TreeOfThoughts:
    def __init__(self, llm, evaluator):
        self.llm = llm
        self.evaluator = evaluator
    
    def solve(self, problem, depth=3, breadth=3):
        thoughts = [{"content": problem, "score": 0, "depth": 0}]
        
        for d in range(depth):
            next_thoughts = []
            
            for thought in thoughts:
                # Generate multiple alternative thoughts
                alternatives = self.generate_alternatives(
                    thought["content"], breadth
                )
                
                for alt in alternatives:
                    score = self.evaluator.evaluate(alt)
                    next_thoughts.append({
                        "content": alt,
                        "score": score,
                        "depth": d + 1,
                        "parent": thought
                    })
            
            # Select best thoughts for next iteration
            thoughts = sorted(next_thoughts, 
                            key=lambda x: x["score"], 
                            reverse=True)[:breadth]
        
        return thoughts[0]  # Return best solution
```

---

## üíæ Memory & State Management

Agents need sophisticated memory systems to maintain context, learn from experience, and coordinate long-term goals.

![Memory Architecture](../assets/memory-architecture.png)
*Multi-layered memory system for agents*

### Types of Memory

**1. Working Memory (Short-term)**
```python
class WorkingMemory:
    def __init__(self, capacity=7):  # Miller's magic number
        self.capacity = capacity
        self.items = []
    
    def add(self, item):
        if len(self.items) >= self.capacity:
            # Remove oldest item (FIFO)
            self.items.pop(0)
        self.items.append(item)
    
    def get_context(self):
        return "\n".join([str(item) for item in self.items])
    
    def clear(self):
        self.items = []
```

**2. Episodic Memory (Experiences)**
```python
class EpisodicMemory:
    def __init__(self, vector_store):
        self.vector_store = vector_store
    
    def store_episode(self, experience):
        episode = {
            "timestamp": datetime.now(),
            "context": experience.context,
            "action": experience.action,
            "outcome": experience.outcome,
            "success": experience.success,
            "lessons": experience.lessons
        }
        
        # Store with semantic search capability
        embedding = self.embed_episode(episode)
        self.vector_store.add(episode, embedding)
    
    def recall_similar_experiences(self, current_situation):
        query_embedding = self.embed_situation(current_situation)
        similar_episodes = self.vector_store.search(
            query_embedding, top_k=5
        )
        return similar_episodes
    
    def learn_from_experience(self, new_experience):
        # Find similar past experiences
        similar = self.recall_similar_experiences(new_experience.context)
        
        # Extract patterns and lessons
        patterns = self.extract_patterns(similar + [new_experience])
        
        # Update knowledge base
        self.update_knowledge(patterns)
```

**3. Semantic Memory (Knowledge)**
```python
class SemanticMemory:
    def __init__(self):
        self.knowledge_graph = KnowledgeGraph()
        self.facts = FactStore()
        self.rules = RuleEngine()
    
    def store_fact(self, fact):
        self.facts.add(fact)
        self.knowledge_graph.add_fact(fact)
    
    def store_rule(self, rule):
        self.rules.add(rule)
    
    def query_knowledge(self, query):
        # Graph-based reasoning
        graph_results = self.knowledge_graph.query(query)
        
        # Rule-based inference
        rule_results = self.rules.infer(query)
        
        # Combine results
        return self.combine_knowledge(graph_results, rule_results)
```

### Memory Integration

```python
class AgentMemorySystem:
    def __init__(self):
        self.working = WorkingMemory()
        self.episodic = EpisodicMemory(vector_store)
        self.semantic = SemanticMemory()
    
    def process_experience(self, experience):
        # Add to working memory
        self.working.add(experience)
        
        # Store in episodic memory if significant
        if self.is_significant(experience):
            self.episodic.store_episode(experience)
        
        # Extract facts for semantic memory
        facts = self.extract_facts(experience)
        for fact in facts:
            self.semantic.store_fact(fact)
    
    def get_relevant_context(self, current_situation):
        context = {}
        
        # Working memory context
        context["immediate"] = self.working.get_context()
        
        # Relevant experiences
        context["experiences"] = self.episodic.recall_similar_experiences(
            current_situation
        )
        
        # Relevant knowledge
        context["knowledge"] = self.semantic.query_knowledge(
            current_situation
        )
        
        return context
```

---

## ü§ù Multi-Agent Coordination

Complex problems often require multiple agents working together, each with specialized capabilities.

![Multi-Agent Systems](../assets/multi-agent-systems.png)
*Different patterns for multi-agent coordination*

### Coordination Patterns

**1. Hierarchical (Manager-Worker)**
```python
class ManagerAgent:
    def __init__(self, worker_agents):
        self.workers = worker_agents
        self.task_queue = []
    
    def coordinate_task(self, complex_task):
        # Decompose task
        subtasks = self.decompose_task(complex_task)
        
        # Assign to workers based on capabilities
        assignments = {}
        for subtask in subtasks:
            best_worker = self.select_best_worker(subtask)
            assignments[subtask.id] = best_worker
        
        # Monitor progress and coordinate
        results = {}
        for subtask_id, worker in assignments.items():
            result = worker.execute_task(subtasks[subtask_id])
            results[subtask_id] = result
        
        # Integrate results
        return self.integrate_results(complex_task, results)
    
    def select_best_worker(self, subtask):
        best_score = 0
        best_worker = None
        
        for worker in self.workers:
            score = worker.capability_score(subtask)
            if score > best_score:
                best_score = score
                best_worker = worker
        
        return best_worker
```

**2. Peer-to-Peer (Collaborative)**
```python
class CollaborativeAgent:
    def __init__(self, agent_id, specialization):
        self.id = agent_id
        self.specialization = specialization
        self.peers = []
        self.shared_memory = SharedMemory()
    
    def collaborate_on_task(self, task):
        # Broadcast task to relevant peers
        relevant_peers = self.find_relevant_peers(task)
        
        # Form temporary team
        team = AgentTeam([self] + relevant_peers)
        
        # Distributed problem solving
        return team.solve_collaboratively(task)
    
    def negotiate_role(self, task, team):
        # Assess own capabilities
        my_capability = self.assess_capability(task)
        
        # Propose role based on specialization
        proposed_role = self.propose_role(task, my_capability)
        
        # Negotiate with team
        assigned_role = team.negotiate_roles({
            self.id: proposed_role
        })
        
        return assigned_role[self.id]

class AgentTeam:
    def __init__(self, agents):
        self.agents = agents
        self.communication_channel = CommunicationChannel()
    
    def solve_collaboratively(self, task):
        # Negotiate roles
        roles = self.negotiate_roles(task)
        
        # Coordinate execution
        solution_parts = {}
        
        for agent in self.agents:
            role = roles[agent.id]
            part_solution = agent.execute_role(task, role)
            solution_parts[agent.id] = part_solution
            
            # Share progress with team
            self.communication_channel.broadcast(
                f"{agent.id} completed {role.description}"
            )
        
        # Integrate solutions
        return self.integrate_solutions(solution_parts)
```

**3. Market-Based (Auction)**
```python
class MarketAgent:
    def __init__(self, agent_id, resources, capabilities):
        self.id = agent_id
        self.resources = resources
        self.capabilities = capabilities
        self.reputation = 1.0
    
    def bid_for_task(self, task):
        # Calculate cost and capability
        cost = self.calculate_cost(task)
        capability = self.assess_capability(task)
        
        # Factor in reputation
        confidence = self.reputation * capability
        
        # Submit bid
        bid = Bid(
            agent_id=self.id,
            cost=cost,
            quality_estimate=confidence,
            completion_time=self.estimate_time(task)
        )
        
        return bid
    
    def execute_contracted_task(self, task, contract):
        start_time = time.time()
        
        try:
            result = self.execute_task(task)
            completion_time = time.time() - start_time
            
            # Update reputation based on performance
            performance = self.evaluate_performance(
                result, contract.expected_quality
            )
            self.update_reputation(performance)
            
            return result
            
        except Exception as e:
            # Penalize reputation for failure
            self.reputation *= 0.9
            raise e

class TaskAuctioneer:
    def __init__(self, agents):
        self.agents = agents
    
    def auction_task(self, task):
        # Collect bids
        bids = []
        for agent in self.agents:
            if agent.can_handle(task):
                bid = agent.bid_for_task(task)
                bids.append(bid)
        
        # Select best bid (multi-criteria)
        best_bid = self.select_best_bid(bids, task)
        
        # Award contract
        contract = Contract(
            task=task,
            agent_id=best_bid.agent_id,
            agreed_cost=best_bid.cost,
            deadline=best_bid.completion_time
        )
        
        return contract
```

### Communication Protocols

```python
class AgentCommunication:
    def __init__(self):
        self.message_queue = MessageQueue()
        self.protocols = {
            'request': self.handle_request,
            'inform': self.handle_inform,
            'query': self.handle_query,
            'propose': self.handle_propose,
            'accept': self.handle_accept,
            'reject': self.handle_reject
        }
    
    def send_message(self, sender, receiver, message_type, content):
        message = Message(
            sender=sender,
            receiver=receiver,
            type=message_type,
            content=content,
            timestamp=datetime.now()
        )
        
        self.message_queue.send(message)
    
    def process_messages(self, agent):
        messages = self.message_queue.get_messages_for(agent.id)
        
        for message in messages:
            handler = self.protocols.get(message.type)
            if handler:
                handler(agent, message)
    
    def handle_request(self, agent, message):
        # Another agent is requesting help
        request = message.content
        
        if agent.can_help_with(request):
            response = agent.process_request(request)
            self.send_message(
                agent.id, message.sender, 'inform', response
            )
        else:
            self.send_message(
                agent.id, message.sender, 'reject', 
                f"Cannot help with {request.type}"
            )
```

---

## üåç Real-World Agent Applications

Let's explore how agentic AI is being applied across different domains.

![Agent Applications](../assets/agent-applications.png)
*Real-world applications of agentic AI systems*

### 1. Research Assistant Agents

```python
class ResearchAgent:
    def __init__(self, name, specialization):
        self.name = name
        self.specialization = specialization
        self.tools = {
            'search': AcademicSearchTool(),
            'analyze': PaperAnalysisTool(),
            'summarize': SummarizationTool(),
            'cite': CitationTool()
        }
    
    def conduct_research(self, research_question):
        # Phase 1: Literature search
        papers = self.search_literature(research_question)
        
        # Phase 2: Analysis
        key_findings = []
        for paper in papers:
            analysis = self.analyze_paper(paper, research_question)
            key_findings.append(analysis)
        
        # Phase 3: Synthesis
        synthesis = self.synthesize_findings(key_findings)
        
        # Phase 4: Generate report
        report = self.generate_research_report(
            research_question, key_findings, synthesis
        )
        
        return report
    
    def search_literature(self, question):
        # Extract key terms
        key_terms = self.extract_key_terms(question)
        
        # Search multiple databases
        papers = []
        for database in ['arxiv', 'pubmed', 'google_scholar']:
            results = self.tools['search'].search(
                database, key_terms, limit=10
            )
            papers.extend(results)
        
        # Filter and rank by relevance
        relevant_papers = self.filter_relevant(papers, question)
        return relevant_papers[:20]  # Top 20 papers
```

### 2. Customer Service Agents

```python
class CustomerServiceAgent:
    def __init__(self):
        self.knowledge_base = CustomerKnowledgeBase()
        self.tools = {
            'lookup_order': OrderLookupTool(),
            'process_refund': RefundTool(),
            'escalate': EscalationTool(),
            'send_email': EmailTool()
        }
        self.conversation_memory = ConversationMemory()
    
    def handle_customer_inquiry(self, customer_id, message):
        # Understand intent
        intent = self.classify_intent(message)
        
        # Route to appropriate handler
        if intent == 'order_inquiry':
            return self.handle_order_inquiry(customer_id, message)
        elif intent == 'refund_request':
            return self.handle_refund_request(customer_id, message)
        elif intent == 'technical_support':
            return self.handle_technical_support(customer_id, message)
        else:
            return self.handle_general_inquiry(customer_id, message)
    
    def handle_order_inquiry(self, customer_id, message):
        # Extract order information
        order_details = self.extract_order_details(message)
        
        # Lookup order
        order = self.tools['lookup_order'].search(
            customer_id, order_details
        )
        
        if order:
            status_update = self.generate_status_update(order)
            return status_update
        else:
            # Escalate if order not found
            return self.tools['escalate'].create_ticket(
                customer_id, "Order not found", message
            )
```

### 3. Trading and Finance Agents

```python
class TradingAgent:
    def __init__(self, strategy, risk_manager):
        self.strategy = strategy
        self.risk_manager = risk_manager
        self.portfolio = Portfolio()
        self.market_data = MarketDataFeed()
        
    def autonomous_trading_loop(self):
        while self.is_market_open():
            # Gather market data
            market_state = self.market_data.get_current_state()
            
            # Analyze opportunities
            opportunities = self.strategy.identify_opportunities(
                market_state, self.portfolio
            )
            
            # Risk assessment
            approved_trades = []
            for opportunity in opportunities:
                risk_assessment = self.risk_manager.assess_risk(
                    opportunity, self.portfolio
                )
                
                if risk_assessment.approved:
                    approved_trades.append(opportunity)
            
            # Execute trades
            for trade in approved_trades:
                execution_result = self.execute_trade(trade)
                self.update_portfolio(execution_result)
            
            # Sleep until next cycle
            time.sleep(self.strategy.update_interval)
    
    def execute_trade(self, trade_opportunity):
        # Pre-execution checks
        if not self.pre_execution_checks(trade_opportunity):
            return None
        
        # Execute trade
        order = Order(
            symbol=trade_opportunity.symbol,
            side=trade_opportunity.side,
            quantity=trade_opportunity.quantity,
            order_type=trade_opportunity.order_type
        )
        
        execution_result = self.broker.execute_order(order)
        
        # Post-execution analysis
        self.analyze_execution_quality(execution_result)
        
        return execution_result
```

### 4. Creative Content Agents

```python
class CreativeWritingAgent:
    def __init__(self, style, expertise):
        self.style = style
        self.expertise = expertise
        self.research_agent = ResearchAgent("research", expertise)
        self.tools = {
            'grammar_check': GrammarChecker(),
            'style_analysis': StyleAnalyzer(),
            'plagiarism_check': PlagiarismChecker(),
            'fact_check': FactChecker()
        }
    
    def write_article(self, topic, requirements):
        # Research phase
        research = self.research_agent.conduct_research(topic)
        
        # Planning phase
        outline = self.create_outline(topic, research, requirements)
        
        # Writing phase
        draft = self.write_draft(outline, research)
        
        # Revision phase
        revised_draft = self.revise_content(draft, requirements)
        
        # Quality assurance
        final_article = self.quality_check(revised_draft)
        
        return final_article
    
    def create_outline(self, topic, research, requirements):
        prompt = f"""
        Create a detailed outline for an article on: {topic}
        
        Based on this research: {research.summary}
        
        Requirements:
        - Length: {requirements.word_count} words
        - Audience: {requirements.target_audience}
        - Style: {self.style}
        - Include: {requirements.must_include}
        
        Outline:"""
        
        outline_text = self.llm.generate(prompt)
        return self.parse_outline(outline_text)
```

---

## üõ°Ô∏è Agent Safety & Control

As agents become more autonomous, ensuring they operate safely and within intended boundaries becomes crucial.

![Agent Safety Framework](../assets/agent-safety.png)
*Multi-layered approach to agent safety and control*

### Safety Principles

**1. Value Alignment**
Ensure agents pursue intended goals and values.

```python
class ValueAlignmentModule:
    def __init__(self, human_values, reward_model):
        self.values = human_values
        self.reward_model = reward_model
    
    def evaluate_action(self, action, context):
        # Check against core values
        value_score = self.assess_value_alignment(action, self.values)
        
        # Predict consequences
        predicted_outcomes = self.predict_outcomes(action, context)
        
        # Evaluate outcomes against values
        outcome_scores = [
            self.assess_value_alignment(outcome, self.values)
            for outcome in predicted_outcomes
        ]
        
        # Combine scores
        overall_score = self.combine_scores(
            value_score, outcome_scores
        )
        
        return overall_score
    
    def should_prevent_action(self, action, context):
        score = self.evaluate_action(action, context)
        return score < self.safety_threshold
```

**2. Capability Control**
Limit what agents can do and access.

```python
class CapabilityController:
    def __init__(self, allowed_tools, access_levels):
        self.allowed_tools = allowed_tools
        self.access_levels = access_levels
        self.action_log = ActionLog()
    
    def authorize_tool_use(self, agent_id, tool_name, parameters):
        # Check if tool is allowed
        if tool_name not in self.allowed_tools[agent_id]:
            return False, "Tool not authorized"
        
        # Check access level requirements
        required_level = self.get_required_access_level(tool_name)
        agent_level = self.access_levels[agent_id]
        
        if agent_level < required_level:
            return False, "Insufficient access level"
        
        # Check parameter safety
        if not self.are_parameters_safe(tool_name, parameters):
            return False, "Unsafe parameters"
        
        # Log authorized action
        self.action_log.log_action(agent_id, tool_name, parameters)
        
        return True, "Authorized"
    
    def escalate_if_needed(self, agent_id, action):
        # Check for patterns that require human oversight
        if self.requires_human_approval(action):
            return self.request_human_approval(agent_id, action)
        
        return True  # No escalation needed
```

**3. Monitoring and Intervention**
Continuously monitor agent behavior and intervene when necessary.

```python
class AgentMonitor:
    def __init__(self, safety_rules, intervention_system):
        self.safety_rules = safety_rules
        self.intervention_system = intervention_system
        self.behavior_analyzer = BehaviorAnalyzer()
    
    def monitor_agent(self, agent):
        while agent.is_active():
            # Collect behavior data
            behavior_data = self.collect_behavior_data(agent)
            
            # Analyze for anomalies
            anomalies = self.behavior_analyzer.detect_anomalies(
                behavior_data
            )
            
            # Check safety rule violations
            violations = self.check_safety_violations(
                behavior_data, self.safety_rules
            )
            
            # Intervene if necessary
            if anomalies or violations:
                self.intervene(agent, anomalies, violations)
            
            time.sleep(self.monitoring_interval)
    
    def intervene(self, agent, anomalies, violations):
        intervention_level = self.determine_intervention_level(
            anomalies, violations
        )
        
        if intervention_level == "PAUSE":
            agent.pause_operations()
            self.alert_human_operators()
        elif intervention_level == "REDIRECT":
            agent.redirect_to_safe_action()
        elif intervention_level == "SHUTDOWN":
            agent.emergency_shutdown()
            self.escalate_to_emergency_team()
```

### Robustness and Reliability

**Error Handling and Recovery**
```python
class RobustAgent:
    def __init__(self, core_agent, fallback_strategies):
        self.core_agent = core_agent
        self.fallback_strategies = fallback_strategies
        self.error_tracker = ErrorTracker()
    
    def execute_with_fallback(self, task):
        attempt = 0
        last_error = None
        
        # Try primary approach
        try:
            return self.core_agent.execute(task)
        except Exception as e:
            last_error = e
            self.error_tracker.log_error(e, task)
        
        # Try fallback strategies
        for strategy in self.fallback_strategies:
            attempt += 1
            try:
                return strategy.execute(task)
            except Exception as e:
                last_error = e
                self.error_tracker.log_error(e, task, strategy=strategy)
        
        # All strategies failed
        self.handle_complete_failure(task, last_error)
        return None
    
    def handle_complete_failure(self, task, error):
        # Log failure
        self.error_tracker.log_complete_failure(task, error)
        
        # Notify human operators
        self.notify_operators(task, error)
        
        # Graceful degradation
        return self.provide_fallback_response(task)
```

---

## üß™ Knowledge Check

Test your understanding of agentic AI:

### Question 1: Agent Characteristics
What distinguishes agentic AI from traditional AI systems?
- A) Better accuracy
- B) Faster processing
- C) Autonomous goal-directed behavior ‚úÖ
- D) Larger model size

**Explanation**: Agentic AI systems can set goals, make plans, and take actions autonomously, unlike traditional reactive systems.

### Question 2: Planning Strategies
Which planning approach is best for complex, multi-step tasks with dependencies?
- A) Reactive planning
- B) Forward planning
- C) Hierarchical planning ‚úÖ
- D) Random planning

**Explanation**: Hierarchical planning breaks complex tasks into manageable subtasks, handling dependencies effectively.

### Question 3: Multi-Agent Coordination
In what scenario would you use a market-based coordination mechanism?
- A) When agents have identical capabilities
- B) When resources are unlimited
- C) When agents compete for limited resources ‚úÖ
- D) When tasks are simple

**Explanation**: Market-based mechanisms efficiently allocate resources among competing agents through bidding and contracts.

---

## üéØ Hands-on Project

**Project**: Build a Multi-Agent Research Team

**Objective**: Create a system where specialized agents collaborate to conduct comprehensive research on any topic.

### Agent Specifications

```python
# Research Coordinator Agent
class ResearchCoordinator:
    def __init__(self):
        self.specialists = {
            'literature_review': LiteratureReviewAgent(),
            'data_analysis': DataAnalysisAgent(), 
            'fact_checking': FactCheckingAgent(),
            'writing': WritingAgent()
        }
    
    def coordinate_research(self, research_question):
        # Phase 1: Initial planning
        research_plan = self.create_research_plan(research_question)
        
        # Phase 2: Parallel research execution
        results = {}
        for task in research_plan.parallel_tasks:
            agent = self.specialists[task.type]
            results[task.id] = agent.execute_task(task)
        
        # Phase 3: Integration and synthesis
        final_report = self.integrate_findings(results)
        
        return final_report

# Literature Review Agent
class LiteratureReviewAgent:
    def __init__(self):
        self.tools = {
            'academic_search': AcademicSearchTool(),
            'paper_analyzer': PaperAnalysisTool(),
            'citation_tracker': CitationTracker()
        }
    
    def execute_task(self, task):
        # Search for relevant papers
        papers = self.tools['academic_search'].search(
            task.keywords, limit=50
        )
        
        # Analyze and summarize papers
        summaries = []
        for paper in papers:
            summary = self.tools['paper_analyzer'].summarize(paper)
            summaries.append(summary)
        
        # Create literature review
        review = self.synthesize_literature(summaries, task.focus)
        
        return review

# Data Analysis Agent  
class DataAnalysisAgent:
    def __init__(self):
        self.tools = {
            'data_collector': DataCollectionTool(),
            'statistical_analyzer': StatisticalAnalyzer(),
            'visualization': VisualizationTool()
        }
    
    def execute_task(self, task):
        # Collect relevant data
        data = self.tools['data_collector'].collect(task.data_requirements)
        
        # Perform statistical analysis
        analysis = self.tools['statistical_analyzer'].analyze(
            data, task.analysis_type
        )
        
        # Create visualizations
        charts = self.tools['visualization'].create_charts(
            data, analysis
        )
        
        return {
            'analysis': analysis,
            'visualizations': charts,
            'insights': self.extract_insights(analysis)
        }
```

### Implementation Steps

**Step 1: Agent Framework**
```python
# Base agent class
class BaseAgent:
    def __init__(self, name, specialization):
        self.name = name
        self.specialization = specialization
        self.memory = AgentMemory()
        self.communication = AgentCommunication()
    
    def execute_task(self, task):
        raise NotImplementedError
    
    def collaborate_with(self, other_agent, shared_task):
        # Implement collaboration protocol
        pass

# Communication system
class AgentCommunication:
    def __init__(self):
        self.message_bus = MessageBus()
    
    def send_request(self, recipient, request):
        message = Message(
            type='request',
            content=request,
            sender=self.agent_id,
            recipient=recipient
        )
        self.message_bus.send(message)
    
    def broadcast_finding(self, finding):
        message = Message(
            type='broadcast',
            content=finding,
            sender=self.agent_id
        )
        self.message_bus.broadcast(message)
```

**Step 2: Task Coordination**
```python
class TaskCoordinator:
    def __init__(self, agents):
        self.agents = agents
        self.task_scheduler = TaskScheduler()
    
    def coordinate_research_project(self, project):
        # Decompose project into tasks
        tasks = self.decompose_project(project)
        
        # Create dependency graph
        dependency_graph = self.create_dependency_graph(tasks)
        
        # Schedule tasks
        schedule = self.task_scheduler.schedule(
            tasks, dependency_graph, self.agents
        )
        
        # Execute scheduled tasks
        results = self.execute_schedule(schedule)
        
        return results
```

### Expected Outcomes
- ‚úÖ Comprehensive research reports on any topic
- ‚úÖ Coordinated agent collaboration
- ‚úÖ Efficient task distribution and execution
- ‚úÖ Quality synthesis of multi-source information

### Evaluation Criteria
- **Completeness**: Coverage of research topic
- **Accuracy**: Fact-checking and verification
- **Efficiency**: Time to complete research
- **Coordination**: Effective agent collaboration

---

## üéâ Summary

You've mastered the fascinating world of agentic AI! You now understand:

‚úÖ **Agent Architectures** and design patterns
‚úÖ **Tool Integration** and function calling
‚úÖ **Planning & Reasoning** strategies
‚úÖ **Memory Systems** for agent state management
‚úÖ **Multi-Agent Coordination** patterns
‚úÖ **Real-World Applications** across domains
‚úÖ **Safety & Control** mechanisms
‚úÖ **Production Implementation** considerations

### Key Takeaways

1. **Autonomy is Key**: Agentic AI's power comes from autonomous goal pursuit
2. **Planning Matters**: Sophisticated planning enables complex task completion
3. **Tools Extend Capabilities**: External tool integration dramatically expands what agents can do
4. **Coordination Scales Impact**: Multiple agents can solve problems beyond individual capabilities
5. **Safety is Critical**: Autonomous systems require careful safety measures

### The Future of Agentic AI

Agentic AI is rapidly evolving toward:
- **More Sophisticated Reasoning**: Better planning and problem-solving
- **Seamless Human-AI Collaboration**: Natural interaction patterns
- **Domain Specialization**: Expert agents for specific fields
- **Ethical AI Systems**: Built-in value alignment and safety

### What's Next?

In **Part 10**, we'll explore **AI Safety, Ethics, and Responsible AI**, crucial topics for building trustworthy agentic systems that benefit humanity.

---

## üìñ Series Navigation

**Previous**: [Part 8: Vector Databases & Embeddings ‚Üê](/posts/genai-mastery-series/part-8)
**Next**: [Part 10: AI Safety, Ethics, and Responsible AI ‚Üí](/posts/genai-mastery-series/part-10)

**Jump to**:
- [Part 11: Production AI Applications ‚Üí](/posts/genai-mastery-series/part-11)
- [Part 12: Future of AI ‚Üí](/posts/genai-mastery-series/part-12)

---

*Ready to explore the responsible development of AI systems? AI safety and ethics await in Part 10!*
