## Understanding Composite Indexes

Composite indexes (also called compound or multi-column indexes) include multiple columns in a single index structure. The order of columns in composite indexes is crucial for query performance.

### The Index Column Order Principle

```sql
-- Example table
CREATE TABLE sales (
    id INT PRIMARY KEY,
    customer_id INT,
    product_id INT,
    sale_date DATE,
    amount DECIMAL(10,2),
    region VARCHAR(50),
    salesperson_id INT
);

-- Composite index with specific column order
CREATE INDEX idx_sales_composite ON sales(customer_id, sale_date, amount);
```

### How Composite Indexes Work

```
Index Structure: (customer_id, sale_date, amount)
┌─────────────┬─────────────┬────────┬──────────┐
│ customer_id │ sale_date   │ amount │ Row Ptr  │
├─────────────┼─────────────┼────────┼──────────┤
│     100     │ 2024-01-15  │  250.0 │   →      │
│     100     │ 2024-01-20  │  175.0 │   →      │
│     100     │ 2024-02-10  │  300.0 │   →      │
│     101     │ 2024-01-12  │  450.0 │   →      │
│     101     │ 2024-01-25  │  200.0 │   →      │
└─────────────┴─────────────┴────────┴──────────┘
```

### Query Efficiency with Composite Indexes

```sql
-- HIGHLY EFFICIENT: Uses full index
SELECT * FROM sales 
WHERE customer_id = 100 
  AND sale_date BETWEEN '2024-01-01' AND '2024-01-31'
  AND amount > 200;

-- EFFICIENT: Uses index prefix (customer_id, sale_date)
SELECT * FROM sales 
WHERE customer_id = 100 
  AND sale_date BETWEEN '2024-01-01' AND '2024-01-31';

-- EFFICIENT: Uses index prefix (customer_id)
SELECT * FROM sales WHERE customer_id = 100;

-- INEFFICIENT: Cannot use index effectively
SELECT * FROM sales WHERE sale_date = '2024-01-15';  -- Missing customer_id prefix

-- INEFFICIENT: Cannot use index effectively  
SELECT * FROM sales WHERE amount > 200;  -- Missing customer_id and sale_date prefix
```

## Optimal Column Ordering Strategies

### The ESR Rule (Equality, Sort, Range)

```sql
-- Query pattern analysis
SELECT * FROM orders 
WHERE customer_id = ?          -- Equality
  AND status = ?               -- Equality  
ORDER BY order_date DESC       -- Sort
  AND total_amount > ?;        -- Range

-- Optimal index order: Equality → Sort → Range
CREATE INDEX idx_orders_esr ON orders(customer_id, status, order_date, total_amount);
```

### Selectivity-Based Ordering

```sql
-- High selectivity (many unique values) → Low selectivity (few unique values)
CREATE INDEX idx_users_selective ON users(
    email,        -- High selectivity (unique emails)
    age,          -- Medium selectivity  
    status        -- Low selectivity ('active', 'inactive', 'pending')
);

-- Check column selectivity
SELECT 
    COUNT(DISTINCT email) / COUNT(*) as email_selectivity,
    COUNT(DISTINCT age) / COUNT(*) as age_selectivity,
    COUNT(DISTINCT status) / COUNT(*) as status_selectivity
FROM users;
```

### Frequency-Based Ordering

```sql
-- Most frequently queried columns first
-- Analysis shows: 80% of queries filter by region, 60% by date, 30% by salesperson

CREATE INDEX idx_sales_frequency ON sales(
    region,           -- Used in 80% of queries (most frequent)
    sale_date,        -- Used in 60% of queries
    salesperson_id    -- Used in 30% of queries
);
```

## Advanced Composite Index Techniques

### Index Intersection vs Single Composite Index

```sql
-- Option 1: Multiple single-column indexes
CREATE INDEX idx_customer ON sales(customer_id);
CREATE INDEX idx_date ON sales(sale_date);
CREATE INDEX idx_amount ON sales(amount);

-- Option 2: Single composite index
CREATE INDEX idx_composite ON sales(customer_id, sale_date, amount);

-- Query performance comparison
SELECT * FROM sales 
WHERE customer_id = 100 
  AND sale_date >= '2024-01-01' 
  AND amount > 200;

-- Option 1: Database may use index intersection (combining multiple indexes)
-- Option 2: Single index lookup (generally more efficient)
```

### Covering Indexes (Include Columns)

```sql
-- SQL Server: INCLUDE additional columns at leaf level
CREATE NONCLUSTERED INDEX idx_sales_covering 
ON sales(customer_id, sale_date) 
INCLUDE (amount, product_id, salesperson_id);

-- This query can be satisfied entirely from the index
SELECT customer_id, sale_date, amount, product_id 
FROM sales 
WHERE customer_id = 100 AND sale_date >= '2024-01-01';

-- PostgreSQL: Add extra columns to create covering index
CREATE INDEX idx_sales_covering ON sales(customer_id, sale_date, amount, product_id, salesperson_id);

-- MySQL: Include all needed columns in the index
CREATE INDEX idx_sales_covering ON sales(customer_id, sale_date, amount, product_id, salesperson_id);
```

### Partial Composite Indexes

```sql
-- PostgreSQL: Index only relevant data
CREATE INDEX idx_active_customer_sales 
ON sales(customer_id, sale_date) 
WHERE status = 'completed' AND amount > 0;

-- SQL Server: Filtered index
CREATE INDEX idx_active_customer_sales 
ON sales(customer_id, sale_date) 
WHERE status = 'completed' AND amount > 0;

-- Benefits: Smaller index size, faster maintenance, targeted queries
```

## Query Optimization Techniques

### Analyzing Query Execution Plans

#### MySQL Query Analysis
```sql
-- Basic explain
EXPLAIN SELECT * FROM sales 
WHERE customer_id = 100 AND sale_date >= '2024-01-01';

-- Extended explain with cost information
EXPLAIN FORMAT=JSON 
SELECT * FROM sales 
WHERE customer_id = 100 AND sale_date >= '2024-01-01'
ORDER BY sale_date DESC;

-- Analyze actual execution
EXPLAIN ANALYZE 
SELECT * FROM sales 
WHERE customer_id = 100 AND sale_date >= '2024-01-01';
```

#### PostgreSQL Query Analysis
```sql
-- Basic execution plan
EXPLAIN SELECT * FROM sales 
WHERE customer_id = 100 AND sale_date >= '2024-01-01';

-- Detailed execution plan with costs
EXPLAIN (ANALYZE, COSTS, BUFFERS) 
SELECT * FROM sales 
WHERE customer_id = 100 AND sale_date >= '2024-01-01';

-- JSON format for programmatic analysis
EXPLAIN (ANALYZE, COSTS, BUFFERS, FORMAT JSON) 
SELECT * FROM sales 
WHERE customer_id = 100 AND sale_date >= '2024-01-01';
```

#### SQL Server Query Analysis
```sql
-- Show execution plan
SET SHOWPLAN_ALL ON;
SELECT * FROM sales 
WHERE customer_id = 100 AND sale_date >= '2024-01-01';

-- Include actual execution statistics
SET STATISTICS IO ON;
SET STATISTICS TIME ON;
SELECT * FROM sales 
WHERE customer_id = 100 AND sale_date >= '2024-01-01';

-- Use SQL Server Management Studio for graphical plans
```

### Index Hints and Forcing

```sql
-- MySQL: Force specific index usage
SELECT * FROM sales USE INDEX (idx_sales_composite)
WHERE customer_id = 100 AND sale_date >= '2024-01-01';

-- PostgreSQL: No direct index hints, but can disable other access methods
SET enable_seqscan = off;
SELECT * FROM sales WHERE customer_id = 100;
SET enable_seqscan = on;

-- SQL Server: Index hints
SELECT * FROM sales WITH (INDEX(idx_sales_composite))
WHERE customer_id = 100 AND sale_date >= '2024-01-01';

-- Oracle: Index hints
SELECT /*+ INDEX(sales idx_sales_composite) */ * 
FROM sales 
WHERE customer_id = 100 AND sale_date >= '2024-01-01';
```

## Complex Query Optimization Patterns

### Join Optimization with Composite Indexes

```sql
-- Tables
CREATE TABLE customers (
    id INT PRIMARY KEY,
    email VARCHAR(255),
    region VARCHAR(50),
    status VARCHAR(20)
);

CREATE TABLE orders (
    id INT PRIMARY KEY,
    customer_id INT,
    order_date DATE,
    total_amount DECIMAL(10,2),
    status VARCHAR(20)
);

-- Indexes for join optimization
CREATE INDEX idx_customers_region_status ON customers(region, status);
CREATE INDEX idx_orders_customer_date ON orders(customer_id, order_date);
CREATE INDEX idx_orders_date_amount ON orders(order_date, total_amount);

-- Optimized join query
SELECT c.email, o.order_date, o.total_amount
FROM customers c
JOIN orders o ON c.id = o.customer_id
WHERE c.region = 'West Coast' 
  AND c.status = 'active'
  AND o.order_date >= '2024-01-01'
  AND o.total_amount > 100;
```

### Subquery Optimization

```sql
-- Original inefficient query
SELECT * FROM customers c
WHERE EXISTS (
    SELECT 1 FROM orders o 
    WHERE o.customer_id = c.id 
      AND o.order_date >= '2024-01-01'
);

-- Create index to optimize the subquery
CREATE INDEX idx_orders_customer_date_exists ON orders(customer_id, order_date);

-- Alternative: Convert to JOIN for better performance
SELECT DISTINCT c.*
FROM customers c
JOIN orders o ON c.id = o.customer_id
WHERE o.order_date >= '2024-01-01';
```

### Window Function Optimization

```sql
-- Window function query
SELECT 
    customer_id,
    order_date,
    total_amount,
    ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_date DESC) as rn
FROM orders
WHERE order_date >= '2024-01-01';

-- Optimal index for window function
CREATE INDEX idx_orders_window ON orders(customer_id, order_date DESC);
-- The index supports both the WHERE clause and the window function's PARTITION BY and ORDER BY
```

## Index Maintenance for Composite Indexes

### Monitoring Index Usage

```sql
-- PostgreSQL: Check index usage statistics
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan as index_scans,
    idx_tup_read as tuples_read,
    idx_tup_fetch as tuples_fetched
FROM pg_stat_user_indexes 
WHERE tablename = 'sales'
ORDER BY idx_scan DESC;

-- MySQL: Check index usage with Performance Schema
SELECT 
    object_schema,
    object_name,
    index_name,
    count_read,
    count_write,
    sum_timer_read,
    sum_timer_write
FROM performance_schema.table_io_waits_summary_by_index_usage
WHERE object_schema = 'your_database' 
  AND object_name = 'sales';

-- SQL Server: Index usage statistics
SELECT 
    OBJECT_NAME(s.object_id) AS table_name,
    i.name AS index_name,
    s.user_seeks,
    s.user_scans,
    s.user_lookups,
    s.user_updates
FROM sys.dm_db_index_usage_stats s
JOIN sys.indexes i ON s.object_id = i.object_id AND s.index_id = i.index_id
WHERE OBJECT_NAME(s.object_id) = 'sales';
```

### Identifying Redundant Indexes

```sql
-- Find potentially redundant indexes
-- Index A: (customer_id, sale_date)
-- Index B: (customer_id, sale_date, amount) 
-- Index B can handle all queries that Index A can handle

-- PostgreSQL query to find redundant indexes
SELECT 
    t.schemaname,
    t.tablename,
    c.reltuples::bigint AS rows,
    pg_size_pretty(pg_total_relation_size(c.oid)) AS size,
    ARRAY_AGG(DISTINCT indexname ORDER BY indexname) AS indexes
FROM pg_stat_user_tables t
JOIN pg_class c ON c.relname = t.tablename
JOIN pg_stat_user_indexes i ON i.relid = c.oid
GROUP BY t.schemaname, t.tablename, c.reltuples, c.oid
HAVING COUNT(*) > 1;
```

### Index Fragmentation and Rebuilding

```sql
-- SQL Server: Check index fragmentation
SELECT 
    OBJECT_NAME(i.object_id) AS table_name,
    i.name AS index_name,
    s.avg_fragmentation_in_percent,
    s.page_count
FROM sys.dm_db_index_physical_stats(DB_ID(), NULL, NULL, NULL, 'DETAILED') s
JOIN sys.indexes i ON s.object_id = i.object_id AND s.index_id = i.index_id
WHERE s.avg_fragmentation_in_percent > 10
  AND s.page_count > 1000;

-- Rebuild highly fragmented indexes
ALTER INDEX idx_sales_composite ON sales REBUILD;

-- PostgreSQL: Reindex when needed
REINDEX INDEX idx_sales_composite;

-- MySQL: Optimize table to rebuild indexes
OPTIMIZE TABLE sales;
```

## Performance Testing and Benchmarking

### Creating Test Data for Index Testing

```sql
-- Generate test data
INSERT INTO sales (customer_id, product_id, sale_date, amount, region, salesperson_id)
SELECT 
    (RANDOM() * 10000)::INT + 1,  -- customer_id (1-10000)
    (RANDOM() * 1000)::INT + 1,   -- product_id (1-1000)
    DATE '2023-01-01' + (RANDOM() * 365)::INT,  -- sale_date (2023)
    (RANDOM() * 1000 + 10)::DECIMAL(10,2),      -- amount (10-1010)
    CASE (RANDOM() * 4)::INT 
        WHEN 0 THEN 'North'
        WHEN 1 THEN 'South' 
        WHEN 2 THEN 'East'
        ELSE 'West'
    END,                          -- region
    (RANDOM() * 100)::INT + 1     -- salesperson_id (1-100)
FROM generate_series(1, 1000000); -- 1M rows
```

### A/B Testing Index Performance

```sql
-- Test 1: Without composite index
DROP INDEX IF EXISTS idx_sales_composite;
\timing on
SELECT * FROM sales 
WHERE customer_id = 100 
  AND sale_date >= '2024-01-01' 
  AND amount > 200;
\timing off

-- Test 2: With composite index
CREATE INDEX idx_sales_composite ON sales(customer_id, sale_date, amount);
\timing on
SELECT * FROM sales 
WHERE customer_id = 100 
  AND sale_date >= '2024-01-01' 
  AND amount > 200;
\timing off
```

### Load Testing with Composite Indexes

```python
# Python script for concurrent query testing
import psycopg2
import threading
import time
import random

def run_queries(connection_string, num_queries):
    conn = psycopg2.connect(connection_string)
    cursor = conn.cursor()
    
    start_time = time.time()
    for i in range(num_queries):
        customer_id = random.randint(1, 10000)
        cursor.execute("""
            SELECT * FROM sales 
            WHERE customer_id = %s 
              AND sale_date >= '2024-01-01' 
              AND amount > 200
        """, (customer_id,))
        results = cursor.fetchall()
    
    end_time = time.time()
    print(f"Thread completed {num_queries} queries in {end_time - start_time:.2f} seconds")
    
    cursor.close()
    conn.close()

# Run concurrent load test
threads = []
for i in range(10):  # 10 concurrent threads
    thread = threading.Thread(target=run_queries, args=(connection_string, 100))
    threads.append(thread)
    thread.start()

for thread in threads:
    thread.join()
```

## Best Practices Summary

### Design Principles
1. **Understand Query Patterns**: Analyze actual application queries before creating indexes
2. **Column Order Matters**: Follow ESR rule and consider selectivity
3. **Covering Indexes**: Include frequently accessed columns to avoid table lookups
4. **Partial Indexes**: Filter out irrelevant data to reduce index size

### Maintenance Guidelines
1. **Monitor Usage**: Regularly check index usage statistics
2. **Remove Unused Indexes**: Drop indexes that aren't being used
3. **Rebuild When Needed**: Address fragmentation in high-write environments
4. **Update Statistics**: Keep optimizer statistics current

### Performance Testing
1. **Test with Real Data**: Use production-like data volumes and distributions
2. **Measure Before and After**: Always benchmark performance improvements
3. **Load Testing**: Test under concurrent workloads
4. **Monitor Resources**: Watch CPU, memory, and I/O impact

## Next Steps
In Part 5, we'll dive into index performance monitoring and maintenance strategies, including automated index tuning, fragmentation management, and advanced monitoring techniques across different database platforms.
