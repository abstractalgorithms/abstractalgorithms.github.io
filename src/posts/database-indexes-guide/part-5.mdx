## Index Performance Monitoring Fundamentals

### Key Performance Metrics

#### Query Performance Indicators
- **Query Execution Time**: End-to-end query duration
- **Index Seek vs Index Scan**: Seek is targeted, scan reads entire index
- **Key Lookups**: Additional operations to fetch non-indexed columns
- **Sort Operations**: Whether sorting uses indexes or requires explicit sorting
- **Buffer Cache Hit Ratio**: Percentage of index pages found in memory

#### Index Health Metrics
- **Index Fragmentation**: Physical disorder of index pages
- **Index Usage Statistics**: How frequently indexes are accessed
- **Index Size Growth**: Storage consumption over time
- **Write Performance Impact**: Effect on INSERT/UPDATE/DELETE operations

### Database-Specific Monitoring Tools

#### MySQL Performance Monitoring

```sql
-- Enable Performance Schema
SET GLOBAL performance_schema = ON;

-- Monitor index usage
SELECT 
    object_schema,
    object_name,
    index_name,
    count_read,
    count_write,
    sum_timer_read/1000000000 AS read_time_seconds,
    sum_timer_write/1000000000 AS write_time_seconds
FROM performance_schema.table_io_waits_summary_by_index_usage
WHERE object_schema = 'your_database'
ORDER BY count_read DESC;

-- Check slow queries using indexes
SELECT 
    digest_text,
    count_star,
    avg_timer_wait/1000000000 AS avg_time_seconds,
    sum_rows_examined,
    sum_rows_sent
FROM performance_schema.events_statements_summary_by_digest
WHERE digest_text LIKE '%your_table%'
ORDER BY avg_timer_wait DESC;

-- Index effectiveness analysis
SELECT 
    TABLE_SCHEMA,
    TABLE_NAME,
    INDEX_NAME,
    CARDINALITY,
    CARDINALITY / (SELECT table_rows FROM information_schema.tables 
                   WHERE table_schema = s.TABLE_SCHEMA 
                   AND table_name = s.TABLE_NAME) AS selectivity
FROM information_schema.statistics s
WHERE TABLE_SCHEMA = 'your_database'
ORDER BY selectivity DESC;
```

#### PostgreSQL Monitoring

```sql
-- Index usage statistics
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch,
    idx_scan::float / GREATEST(seq_scan + idx_scan, 1) AS index_usage_ratio
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
ORDER BY idx_scan DESC;

-- Unused indexes (potential candidates for removal)
SELECT 
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) AS size
FROM pg_stat_user_indexes
WHERE idx_scan = 0 
  AND schemaname = 'public'
ORDER BY pg_relation_size(indexrelid) DESC;

-- Index bloat analysis
SELECT 
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) AS size,
    CASE 
        WHEN indisunique THEN 'UNIQUE'
        ELSE 'NON-UNIQUE'
    END AS index_type,
    n_tup_ins + n_tup_upd + n_tup_del AS total_writes,
    idx_scan AS total_scans
FROM pg_stat_user_indexes 
JOIN pg_stat_user_tables USING (schemaname, tablename)
JOIN pg_index ON indexrelid = pg_index.indexrelid
WHERE schemaname = 'public'
ORDER BY pg_relation_size(indexrelid) DESC;

-- Buffer cache hit ratio for indexes
SELECT 
    schemaname,
    tablename,
    indexname,
    heap_blks_read,
    heap_blks_hit,
    CASE 
        WHEN heap_blks_hit + heap_blks_read = 0 THEN NULL
        ELSE heap_blks_hit::float / (heap_blks_hit + heap_blks_read)
    END AS hit_ratio
FROM pg_statio_user_indexes
WHERE schemaname = 'public'
ORDER BY hit_ratio ASC NULLS LAST;
```

#### SQL Server Monitoring

```sql
-- Index usage statistics
SELECT 
    OBJECT_NAME(i.object_id) AS table_name,
    i.name AS index_name,
    i.type_desc AS index_type,
    dm_ius.user_seeks,
    dm_ius.user_scans,
    dm_ius.user_lookups,
    dm_ius.user_updates,
    dm_ius.user_seeks + dm_ius.user_scans + dm_ius.user_lookups AS total_reads,
    CASE 
        WHEN dm_ius.user_updates > 0 
        THEN (dm_ius.user_seeks + dm_ius.user_scans + dm_ius.user_lookups) / dm_ius.user_updates 
        ELSE NULL 
    END AS read_write_ratio
FROM sys.indexes i
LEFT JOIN sys.dm_db_index_usage_stats dm_ius 
    ON i.object_id = dm_ius.object_id AND i.index_id = dm_ius.index_id
WHERE OBJECTPROPERTY(i.object_id, 'IsUserTable') = 1
ORDER BY total_reads DESC;

-- Index fragmentation analysis
SELECT 
    OBJECT_NAME(i.object_id) AS table_name,
    i.name AS index_name,
    s.avg_fragmentation_in_percent,
    s.fragment_count,
    s.page_count,
    CASE 
        WHEN s.avg_fragmentation_in_percent < 5 THEN 'No action needed'
        WHEN s.avg_fragmentation_in_percent < 30 THEN 'Reorganize'
        ELSE 'Rebuild'
    END AS recommended_action
FROM sys.dm_db_index_physical_stats(DB_ID(), NULL, NULL, NULL, 'DETAILED') s
JOIN sys.indexes i ON s.object_id = i.object_id AND s.index_id = i.index_id
WHERE s.page_count > 100  -- Only consider indexes with significant pages
ORDER BY s.avg_fragmentation_in_percent DESC;

-- Missing index suggestions
SELECT 
    mid.statement AS table_name,
    mids.equality_columns,
    mids.inequality_columns,
    mids.included_columns,
    migs.user_seeks,
    migs.user_scans,
    migs.avg_total_user_cost,
    migs.avg_user_impact,
    'CREATE INDEX idx_' + REPLACE(REPLACE(REPLACE(mid.statement, '[', ''), ']', ''), '.', '_') + 
    '_suggested ON ' + mid.statement + 
    ' (' + ISNULL(mids.equality_columns, '') + 
    CASE WHEN mids.inequality_columns IS NOT NULL 
         THEN CASE WHEN mids.equality_columns IS NOT NULL THEN ',' ELSE '' END + mids.inequality_columns 
         ELSE '' END + ')' +
    CASE WHEN mids.included_columns IS NOT NULL 
         THEN ' INCLUDE (' + mids.included_columns + ')' 
         ELSE '' END AS create_statement
FROM sys.dm_db_missing_index_groups mig
JOIN sys.dm_db_missing_index_group_stats migs ON mig.index_group_handle = migs.group_handle
JOIN sys.dm_db_missing_index_details mid ON mig.index_handle = mid.index_handle
WHERE migs.avg_user_impact > 50  -- High impact suggestions only
ORDER BY migs.avg_user_impact DESC;
```

## Automated Index Maintenance

### SQL Server Automated Maintenance

```sql
-- Create maintenance plan for index optimization
-- This script reorganizes or rebuilds indexes based on fragmentation level

DECLARE @DatabaseName NVARCHAR(50) = 'YourDatabase'
DECLARE @FragmentationThreshold FLOAT = 5.0
DECLARE @RebuildThreshold FLOAT = 30.0

-- Cursor to iterate through fragmented indexes
DECLARE index_cursor CURSOR FOR
SELECT 
    OBJECT_NAME(i.object_id) AS table_name,
    i.name AS index_name,
    s.avg_fragmentation_in_percent,
    CASE 
        WHEN s.avg_fragmentation_in_percent >= @RebuildThreshold THEN 'REBUILD'
        WHEN s.avg_fragmentation_in_percent >= @FragmentationThreshold THEN 'REORGANIZE'
        ELSE 'NO_ACTION'
    END AS action_type
FROM sys.dm_db_index_physical_stats(DB_ID(@DatabaseName), NULL, NULL, NULL, 'DETAILED') s
JOIN sys.indexes i ON s.object_id = i.object_id AND s.index_id = i.index_id
WHERE s.avg_fragmentation_in_percent >= @FragmentationThreshold
  AND s.page_count > 100;

DECLARE @TableName NVARCHAR(128), @IndexName NVARCHAR(128), @Fragmentation FLOAT, @Action NVARCHAR(20)
DECLARE @SQL NVARCHAR(500)

OPEN index_cursor
FETCH NEXT FROM index_cursor INTO @TableName, @IndexName, @Fragmentation, @Action

WHILE @@FETCH_STATUS = 0
BEGIN
    IF @Action = 'REBUILD'
    BEGIN
        SET @SQL = 'ALTER INDEX ' + @IndexName + ' ON ' + @TableName + ' REBUILD WITH (ONLINE = ON)'
        PRINT 'Rebuilding: ' + @IndexName + ' (Fragmentation: ' + CAST(@Fragmentation AS VARCHAR(10)) + '%)'
    END
    ELSE IF @Action = 'REORGANIZE'
    BEGIN
        SET @SQL = 'ALTER INDEX ' + @IndexName + ' ON ' + @TableName + ' REORGANIZE'
        PRINT 'Reorganizing: ' + @IndexName + ' (Fragmentation: ' + CAST(@Fragmentation AS VARCHAR(10)) + '%)'
    END
    
    IF @SQL IS NOT NULL
    BEGIN
        EXEC sp_executesql @SQL
        SET @SQL = NULL
    END
    
    FETCH NEXT FROM index_cursor INTO @TableName, @IndexName, @Fragmentation, @Action
END

CLOSE index_cursor
DEALLOCATE index_cursor
```

### PostgreSQL Automated Maintenance

```bash
#!/bin/bash
# PostgreSQL index maintenance script

DATABASE="your_database"
REINDEX_THRESHOLD=0.2  # 20% bloat threshold

# Function to check index bloat and reindex if necessary
check_and_reindex() {
    psql -d $DATABASE -c "
    DO \$\$
    DECLARE
        idx_record RECORD;
        bloat_query TEXT := '
            SELECT 
                schemaname,
                tablename,
                indexname,
                CASE 
                    WHEN pg_relation_size(indexrelid) = 0 THEN 0
                    ELSE (pg_relation_size(indexrelid)::float / 
                          GREATEST(pg_relation_size(c.oid), 1))
                END AS bloat_ratio
            FROM pg_stat_user_indexes ui
            JOIN pg_class c ON c.relname = ui.tablename
            WHERE schemaname = ''public''
            AND pg_relation_size(indexrelid) > 1000000';  -- Only large indexes
    BEGIN
        FOR idx_record IN EXECUTE bloat_query LOOP
            IF idx_record.bloat_ratio > $REINDEX_THRESHOLD THEN
                RAISE NOTICE 'Reindexing %.% (bloat ratio: %)', 
                    idx_record.indexname, idx_record.tablename, idx_record.bloat_ratio;
                EXECUTE 'REINDEX INDEX CONCURRENTLY ' || idx_record.indexname;
            END IF;
        END LOOP;
    END
    \$\$;
    "
}

# Update table statistics
psql -d $DATABASE -c "
SELECT 'ANALYZE ' || schemaname || '.' || tablename || ';'
FROM pg_stat_user_tables 
WHERE schemaname = 'public'
" | grep ANALYZE | psql -d $DATABASE

# Check and reindex bloated indexes
check_and_reindex

echo "Index maintenance completed"
```

### MySQL Automated Maintenance

```sql
-- MySQL maintenance procedure
DELIMITER //
CREATE PROCEDURE OptimizeIndexes()
BEGIN
    DECLARE done INT DEFAULT FALSE;
    DECLARE table_name VARCHAR(255);
    DECLARE table_cursor CURSOR FOR 
        SELECT TABLE_NAME 
        FROM information_schema.TABLES 
        WHERE TABLE_SCHEMA = DATABASE() 
        AND TABLE_TYPE = 'BASE TABLE';
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;

    OPEN table_cursor;
    
    table_loop: LOOP
        FETCH table_cursor INTO table_name;
        IF done THEN
            LEAVE table_loop;
        END IF;
        
        -- Optimize table (rebuilds indexes)
        SET @sql = CONCAT('OPTIMIZE TABLE ', table_name);
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
        
        -- Analyze table (updates statistics)
        SET @sql = CONCAT('ANALYZE TABLE ', table_name);
        PREPARE stmt FROM @sql;
        EXECUTE stmt;
        DEALLOCATE PREPARE stmt;
        
    END LOOP;
    
    CLOSE table_cursor;
END //
DELIMITER ;

-- Schedule the procedure to run weekly
-- CREATE EVENT weekly_index_maintenance
-- ON SCHEDULE EVERY 1 WEEK
-- STARTS '2024-01-01 02:00:00'
-- DO CALL OptimizeIndexes();
```

## Real-Time Performance Monitoring

### Setting Up Monitoring Dashboards

#### PostgreSQL with pg_stat_statements

```sql
-- Enable pg_stat_statements extension
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- Configure postgresql.conf
-- shared_preload_libraries = 'pg_stat_statements'
-- pg_stat_statements.track = all

-- Query to identify slow queries using indexes
SELECT 
    query,
    calls,
    total_time / calls AS avg_time,
    rows / calls AS avg_rows,
    100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
FROM pg_stat_statements 
WHERE query LIKE '%your_table%'
ORDER BY total_time DESC
LIMIT 10;

-- Reset statistics
SELECT pg_stat_statements_reset();
```

#### MySQL Performance Schema Monitoring

```sql
-- Monitor index usage patterns
SELECT 
    object_schema,
    object_name,
    index_name,
    count_read,
    count_write,
    sum_timer_read / count_read / 1000000000 AS avg_read_time_seconds,
    sum_timer_write / count_write / 1000000000 AS avg_write_time_seconds
FROM performance_schema.table_io_waits_summary_by_index_usage
WHERE count_read > 0 OR count_write > 0
ORDER BY count_read DESC;

-- Monitor statement performance
SELECT 
    DIGEST_TEXT,
    COUNT_STAR,
    AVG_TIMER_WAIT / 1000000000 AS avg_time_seconds,
    SUM_ROWS_EXAMINED / COUNT_STAR AS avg_rows_examined,
    SUM_ROWS_SENT / COUNT_STAR AS avg_rows_sent
FROM performance_schema.events_statements_summary_by_digest
WHERE DIGEST_TEXT IS NOT NULL
ORDER BY AVG_TIMER_WAIT DESC
LIMIT 10;
```

### Application-Level Monitoring

#### Python Application Monitoring

```python
import time
import logging
from functools import wraps

# Query performance decorator
def monitor_query_performance(query_name):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            end_time = time.time()
            
            execution_time = end_time - start_time
            
            # Log slow queries
            if execution_time > 1.0:  # Queries taking more than 1 second
                logging.warning(f"Slow query detected: {query_name} took {execution_time:.2f} seconds")
            
            # Store metrics for analysis
            store_performance_metric(query_name, execution_time, len(result) if result else 0)
            
            return result
        return wrapper
    return decorator

# Usage example
@monitor_query_performance("get_user_orders")
def get_user_orders(user_id, start_date, end_date):
    query = """
    SELECT * FROM orders 
    WHERE customer_id = %s 
      AND order_date BETWEEN %s AND %s
    """
    # Execute query and return results
    return execute_query(query, (user_id, start_date, end_date))

# Performance metrics storage
def store_performance_metric(query_name, execution_time, result_count):
    # Store in time-series database, logging system, or monitoring service
    metrics = {
        'query_name': query_name,
        'execution_time': execution_time,
        'result_count': result_count,
        'timestamp': time.time()
    }
    # Send to monitoring system (e.g., Prometheus, DataDog, etc.)
```

#### Node.js Application Monitoring

```javascript
const queryMonitor = (queryName) => {
    return (target, propertyName, descriptor) => {
        const method = descriptor.value;
        
        descriptor.value = async function(...args) {
            const startTime = Date.now();
            
            try {
                const result = await method.apply(this, args);
                const endTime = Date.now();
                const duration = endTime - startTime;
                
                // Log performance metrics
                console.log(`Query ${queryName}: ${duration}ms`);
                
                // Send to monitoring service
                if (duration > 1000) {
                    console.warn(`Slow query detected: ${queryName} took ${duration}ms`);
                }
                
                return result;
            } catch (error) {
                console.error(`Query ${queryName} failed:`, error);
                throw error;
            }
        };
    };
};

// Usage
class OrderService {
    @queryMonitor('getUserOrders')
    async getUserOrders(userId, startDate, endDate) {
        const query = `
            SELECT * FROM orders 
            WHERE customer_id = ? 
              AND order_date BETWEEN ? AND ?
        `;
        return await this.db.query(query, [userId, startDate, endDate]);
    }
}
```

## Index Performance Alerts

### Setting Up Automated Alerts

#### PostgreSQL Alert Script

```bash
#!/bin/bash
# PostgreSQL performance alert script

DATABASE="your_database"
SLOW_QUERY_THRESHOLD=5.0  # seconds
UNUSED_INDEX_SIZE_THRESHOLD=100  # MB

# Check for slow queries
SLOW_QUERIES=$(psql -d $DATABASE -t -c "
SELECT COUNT(*) 
FROM pg_stat_statements 
WHERE mean_time > $SLOW_QUERY_THRESHOLD * 1000  -- Convert to milliseconds
")

if [ "$SLOW_QUERIES" -gt 0 ]; then
    echo "Alert: $SLOW_QUERIES slow queries detected"
    # Send alert (email, Slack, etc.)
fi

# Check for large unused indexes
UNUSED_INDEXES=$(psql -d $DATABASE -t -c "
SELECT COUNT(*) 
FROM pg_stat_user_indexes 
WHERE idx_scan = 0 
  AND pg_relation_size(indexrelid) > $UNUSED_INDEX_SIZE_THRESHOLD * 1024 * 1024
")

if [ "$UNUSED_INDEXES" -gt 0 ]; then
    echo "Alert: $UNUSED_INDEXES large unused indexes detected"
    # Send alert
fi
```

#### SQL Server Alert Setup

```sql
-- Create alert for high fragmentation
EXEC msdb.dbo.sp_add_alert
    @name = N'High Index Fragmentation',
    @message_id = 50001,
    @severity = 16,
    @enabled = 1;

-- Create custom alert job
EXEC msdb.dbo.sp_add_job
    @job_name = N'Index Health Check';

EXEC msdb.dbo.sp_add_jobstep
    @job_name = N'Index Health Check',
    @step_name = N'Check Fragmentation',
    @command = N'
    IF EXISTS (
        SELECT 1 
        FROM sys.dm_db_index_physical_stats(DB_ID(), NULL, NULL, NULL, ''DETAILED'')
        WHERE avg_fragmentation_in_percent > 30 AND page_count > 1000
    )
    BEGIN
        RAISERROR(''High index fragmentation detected'', 16, 1)
    END';

EXEC msdb.dbo.sp_add_schedule
    @schedule_name = N'Daily Check',
    @freq_type = 4,  -- Daily
    @freq_interval = 1;

EXEC msdb.dbo.sp_attach_schedule
    @job_name = N'Index Health Check',
    @schedule_name = N'Daily Check';
```

## Best Practices for Production Monitoring

### Monitoring Strategy
1. **Baseline Performance**: Establish performance baselines before implementing changes
2. **Continuous Monitoring**: Set up automated monitoring for key metrics
3. **Proactive Alerts**: Configure alerts for performance degradation
4. **Regular Reviews**: Schedule periodic index usage reviews

### Key Metrics to Track
1. **Query Performance**: Execution time, rows examined vs. returned
2. **Index Usage**: Seek/scan ratios, usage frequency
3. **Resource Utilization**: CPU, memory, I/O impact
4. **Fragmentation Levels**: Physical disorder of index pages

### Maintenance Windows
1. **Schedule Regular Maintenance**: Plan index rebuilds during low-activity periods
2. **Test Changes**: Always test index changes in staging environments
3. **Monitor After Changes**: Watch performance closely after index modifications
4. **Rollback Plans**: Have procedures to quickly revert problematic changes

## Next Steps
In Part 6, we'll explore advanced indexing techniques including partitioned indexes, columnar indexes, and specialized indexing strategies for big data and analytics workloads.
