# Space Complexity Deep Dive

While time complexity gets most attention, space complexity is equally crucial in real-world applications. Understanding memory usage patterns helps you build systems that scale efficiently and avoid out-of-memory errors.

## Understanding Space Complexity

Space complexity measures how an algorithm's **memory usage** grows with input size. It includes:

1. **Input space** - memory for the input data
2. **Auxiliary space** - extra memory used by the algorithm
3. **Output space** - memory for the result

> **Important**: Big O space complexity typically refers to **auxiliary space** only – the extra memory beyond the input.

## Input vs Auxiliary Space

### Input Space
```javascript
function processArray(arr) {
  // arr takes O(n) space, but that's input space
  // We don't count this in auxiliary space complexity
  for (let item of arr) {
    console.log(item);
  }
}
// Auxiliary space: O(1)
```

### Auxiliary Space
```javascript
function copyAndReverse(arr) {
  const reversed = [];           // O(n) auxiliary space
  for (let i = arr.length - 1; i >= 0; i--) {
    reversed.push(arr[i]);       // Growing the new array
  }
  return reversed;
}
// Auxiliary space: O(n)
```

## Common Space Complexity Patterns

### O(1) - Constant Space

Algorithms that use a fixed amount of extra memory regardless of input size.

```javascript
// In-place array reversal
function reverseInPlace(arr) {
  let left = 0;                  // O(1) space
  let right = arr.length - 1;    // O(1) space
  
  while (left < right) {
    // Swap elements without extra array
    [arr[left], arr[right]] = [arr[right], arr[left]];
    left++;
    right--;
  }
  return arr;
}
// Space: O(1) - only uses a few variables
```

```javascript
// Finding maximum element
function findMax(arr) {
  let max = arr[0];              // O(1) space
  
  for (let i = 1; i < arr.length; i++) {
    if (arr[i] > max) {
      max = arr[i];              // Still O(1) space
    }
  }
  return max;
}
// Space: O(1) - single variable regardless of array size
```

### O(n) - Linear Space

Memory usage grows proportionally with input size.

```javascript
// Creating a frequency map
function countFrequency(arr) {
  const frequency = {};          // O(n) space in worst case
  
  for (let item of arr) {
    frequency[item] = (frequency[item] || 0) + 1;
  }
  return frequency;
}
// Space: O(n) - map can contain up to n unique elements
```

```javascript
// Implementing stack-based operations
function reverseString(str) {
  const stack = [];              // O(n) space
  
  // Push all characters
  for (let char of str) {
    stack.push(char);
  }
  
  // Pop to create reversed string
  let reversed = '';
  while (stack.length > 0) {
    reversed += stack.pop();
  }
  
  return reversed;
}
// Space: O(n) - stack holds all n characters
```

### O(n²) - Quadratic Space

Memory usage grows quadratically with input size.

```javascript
// Creating a 2D distance matrix
function createDistanceMatrix(points) {
  const n = points.length;
  const matrix = [];             // O(n²) space
  
  for (let i = 0; i < n; i++) {
    matrix[i] = [];
    for (let j = 0; j < n; j++) {
      matrix[i][j] = calculateDistance(points[i], points[j]);
    }
  }
  return matrix;
}
// Space: O(n²) - n×n matrix
```

```javascript
// Dynamic programming table
function longestCommonSubsequence(str1, str2) {
  const m = str1.length;
  const n = str2.length;
  const dp = Array(m + 1).fill().map(() => Array(n + 1).fill(0)); // O(m×n)
  
  for (let i = 1; i <= m; i++) {
    for (let j = 1; j <= n; j++) {
      if (str1[i-1] === str2[j-1]) {
        dp[i][j] = dp[i-1][j-1] + 1;
      } else {
        dp[i][j] = Math.max(dp[i-1][j], dp[i][j-1]);
      }
    }
  }
  return dp[m][n];
}
// Space: O(m×n) - 2D DP table
```

## Recursive Space Complexity

Recursive algorithms use the **call stack**, which consumes memory for each function call.

### Linear Recursive Space - O(n)

```javascript
function factorial(n) {
  if (n <= 1) return 1;          // Base case
  return n * factorial(n - 1);   // Recursive call
}

/*
Call stack analysis:
factorial(5)
  factorial(4)
    factorial(3)
      factorial(2)
        factorial(1) → returns 1
      returns 2
    returns 6
  returns 24
returns 120

Maximum stack depth: 5 = O(n)
Space complexity: O(n)
*/
```

### Logarithmic Recursive Space - O(log n)

```javascript
function binarySearch(arr, target, left = 0, right = arr.length - 1) {
  if (left > right) return -1;
  
  const mid = Math.floor((left + right) / 2);
  
  if (arr[mid] === target) return mid;
  
  if (arr[mid] < target) {
    return binarySearch(arr, target, mid + 1, right);
  } else {
    return binarySearch(arr, target, left, mid - 1);
  }
}

/*
Call stack analysis for array of size 8:
binarySearch(arr, target, 0, 7)    // Search entire array
  binarySearch(arr, target, 4, 7)  // Search right half
    binarySearch(arr, target, 6, 7) // Search smaller portion
      ...

Maximum stack depth: log₂(8) = 3 = O(log n)
Space complexity: O(log n)
*/
```

### Exponential Recursive Space - O(n)

```javascript
function fibonacci(n) {
  if (n <= 1) return n;
  return fibonacci(n - 1) + fibonacci(n - 2);
}

/*
Despite exponential time complexity O(2^n),
space complexity is only O(n) because:

- Maximum stack depth is n (longest path from root to leaf)
- Each call uses O(1) space
- Total space: O(n)

Time: O(2^n), Space: O(n)
*/
```

## Space-Time Tradeoffs

Often, you can trade space for time or vice versa. Understanding these tradeoffs is crucial for optimization.

### Trading Space for Time: Memoization

```javascript
// Time: O(2^n), Space: O(n) - Naive approach
function fibonacciNaive(n) {
  if (n <= 1) return n;
  return fibonacciNaive(n - 1) + fibonacciNaive(n - 2);
}

// Time: O(n), Space: O(n) - Memoized approach
function fibonacciMemo(n, memo = {}) {
  if (n in memo) return memo[n];     // O(1) lookup
  if (n <= 1) return n;
  
  memo[n] = fibonacciMemo(n - 1, memo) + fibonacciMemo(n - 2, memo);
  return memo[n];
}

/*
Tradeoff analysis:
- Naive: Fast space, slow time
- Memoized: More space, much faster time
- Best choice depends on available memory and performance needs
*/
```

### Trading Time for Space: Multiple Passes

```javascript
// One pass, more space: O(n) time, O(n) space
function findTwoSumHashMap(arr, target) {
  const seen = new Map();        // O(n) space
  
  for (let i = 0; i < arr.length; i++) {
    const complement = target - arr[i];
    if (seen.has(complement)) {
      return [seen.get(complement), i];
    }
    seen.set(arr[i], i);
  }
  return null;
}

// Nested loops, less space: O(n²) time, O(1) space
function findTwoSumBruteForce(arr, target) {
  for (let i = 0; i < arr.length; i++) {
    for (let j = i + 1; j < arr.length; j++) {
      if (arr[i] + arr[j] === target) {
        return [i, j];
      }
    }
  }
  return null;
}

/*
Tradeoff:
- HashMap: O(n) time, O(n) space - good for large datasets
- Brute force: O(n²) time, O(1) space - good when memory is limited
*/
```

## In-Place Algorithms

Algorithms that modify input data directly without using significant auxiliary space.

### In-Place Sorting

```javascript
// In-place quicksort: O(log n) average space (recursion stack)
function quicksortInPlace(arr, low = 0, high = arr.length - 1) {
  if (low < high) {
    const pivotIndex = partition(arr, low, high);
    quicksortInPlace(arr, low, pivotIndex - 1);
    quicksortInPlace(arr, pivotIndex + 1, high);
  }
}

function partition(arr, low, high) {
  const pivot = arr[high];
  let i = low - 1;
  
  for (let j = low; j < high; j++) {
    if (arr[j] <= pivot) {
      i++;
      [arr[i], arr[j]] = [arr[j], arr[i]]; // In-place swap
    }
  }
  
  [arr[i + 1], arr[high]] = [arr[high], arr[i + 1]];
  return i + 1;
}
```

### In-Place Array Manipulation

```javascript
// Remove duplicates from sorted array in-place
function removeDuplicates(arr) {
  if (arr.length <= 1) return arr.length;
  
  let writeIndex = 1;            // O(1) space
  
  for (let readIndex = 1; readIndex < arr.length; readIndex++) {
    if (arr[readIndex] !== arr[readIndex - 1]) {
      arr[writeIndex] = arr[readIndex];
      writeIndex++;
    }
  }
  
  return writeIndex; // New length
}
// Space: O(1) - modifies array in place
```

## Space Optimization Techniques

### 1. Reuse Variables

```javascript
// Less optimal: O(n) space
function calculateRunningSum(arr) {
  const result = [];
  let sum = 0;
  
  for (let num of arr) {
    sum += num;
    result.push(sum);
  }
  return result;
}

// More optimal: O(1) auxiliary space (modifying input)
function calculateRunningSumInPlace(arr) {
  for (let i = 1; i < arr.length; i++) {
    arr[i] += arr[i - 1];        // Reuse input array
  }
  return arr;
}
```

### 2. Streaming Processing

```javascript
// Memory-intensive: Load all data
function processLargeFile(filename) {
  const allData = readEntireFile(filename);  // O(file size) space
  return processData(allData);
}

// Memory-efficient: Process in chunks
function processLargeFileStreaming(filename) {
  const stream = createReadStream(filename);
  let result = 0;                            // O(1) space
  
  stream.on('data', chunk => {
    result += processChunk(chunk);           // Process small chunks
  });
  
  return result;
}
```

### 3. Space-Optimized Dynamic Programming

```javascript
// Standard DP: O(n) space
function climbStairsDP(n) {
  const dp = new Array(n + 1);
  dp[0] = 1;
  dp[1] = 1;
  
  for (let i = 2; i <= n; i++) {
    dp[i] = dp[i - 1] + dp[i - 2];
  }
  return dp[n];
}

// Space-optimized: O(1) space
function climbStairsOptimized(n) {
  if (n <= 1) return 1;
  
  let prev2 = 1;                 // dp[i-2]
  let prev1 = 1;                 // dp[i-1]
  
  for (let i = 2; i <= n; i++) {
    const current = prev1 + prev2;
    prev2 = prev1;               // Slide the window
    prev1 = current;
  }
  return prev1;
}
```

## Analyzing Memory Usage

### Stack vs Heap

```javascript
// Stack allocation (function parameters, local variables)
function stackExample(n) {
  let localVar = 5;              // Stack: O(1)
  
  if (n > 0) {
    return stackExample(n - 1);  // Stack: O(n) recursive calls
  }
  return localVar;
}

// Heap allocation (dynamic objects, arrays)
function heapExample(n) {
  const largeArray = new Array(n); // Heap: O(n)
  const obj = { data: largeArray }; // Heap: O(n)
  return obj;
}
```

### Memory Leaks and Cleanup

```javascript
// Potential memory leak
function createClosure(largeData) {
  return function(query) {
    // This closure keeps largeData in memory
    return largeData.includes(query);
  };
}

// Memory-conscious approach
function createEfficientClosure(largeData) {
  const processedData = processAndMinimize(largeData); // Minimize data
  largeData = null;              // Explicit cleanup
  
  return function(query) {
    return processedData.includes(query);
  };
}
```

## Key Takeaways

1. **Space complexity matters** - especially in memory-constrained environments
2. **Distinguish between input and auxiliary space** when analyzing algorithms
3. **Recursive algorithms use stack space** - factor in call stack depth
4. **Space-time tradeoffs** are common - choose based on constraints
5. **In-place algorithms** can dramatically reduce space complexity
6. **Consider memory allocation patterns** - stack vs heap usage
7. **Optimize space when possible** - but don't sacrifice readability unnecessarily

---

Ready for advanced complexity analysis? Next, we'll explore exponential algorithms, amortized analysis, and other advanced concepts.

### What's Next?

**Part 5: Advanced Complexities** - Exponential and factorial time, amortized analysis, and how to handle algorithms that don't fit standard patterns.
