# Advanced Complexities

Beyond the common complexities lie algorithms with exponential growth, factorial behavior, and complex amortized patterns. Understanding these advanced concepts is crucial for tackling difficult problems and making informed algorithmic choices.

## Exponential Time Complexity - O(2ⁿ)

Exponential algorithms double their work with each increase in input size. While often impractical for large inputs, they're sometimes the only known solution to certain problems.

### Characteristics
- **Doubles work** with each additional input
- **Quickly becomes intractable** (unusable for n > 30-40)
- Often appears in **brute force** solutions
- Common in **combinatorial problems**

### Classic Example: Fibonacci (Naive)

```javascript
function fibonacci(n) {
  if (n <= 1) return n;
  return fibonacci(n - 1) + fibonacci(n - 2);
}

/*
Call tree for fibonacci(5):
                    fib(5)
                  /        \
              fib(4)        fib(3)
             /      \      /      \
        fib(3)    fib(2) fib(2)  fib(1)
       /     \    /    \ /    \
   fib(2)  fib(1) fib(1) fib(0) fib(1) fib(0)
   /    \
fib(1) fib(0)

Each level roughly doubles the number of calls.
Total calls ≈ 2^n
Time complexity: O(2^n)
*/
```

### Subset Generation

```javascript
function generateSubsets(nums) {
  const result = [];
  
  function backtrack(index, currentSubset) {
    if (index === nums.length) {
      result.push([...currentSubset]);  // O(n) to copy
      return;
    }
    
    // Include current element
    currentSubset.push(nums[index]);
    backtrack(index + 1, currentSubset);
    
    // Exclude current element
    currentSubset.pop();
    backtrack(index + 1, currentSubset);
  }
  
  backtrack(0, []);
  return result;
}

/*
Analysis:
- 2 choices per element (include/exclude)
- n elements total
- Total subsets: 2^n
- Time: O(n × 2^n) - copying takes O(n) time
- Space: O(n × 2^n) - storing all subsets
*/
```

### Traveling Salesman Problem (Brute Force)

```javascript
function tspBruteForce(distances) {
  const n = distances.length;
  const cities = Array.from({ length: n }, (_, i) => i);
  let minCost = Infinity;
  
  function permute(arr, start = 0) {
    if (start === arr.length - 1) {
      const cost = calculateTourCost(arr, distances);
      minCost = Math.min(minCost, cost);
      return;
    }
    
    for (let i = start; i < arr.length; i++) {
      [arr[start], arr[i]] = [arr[i], arr[start]];
      permute(arr, start + 1);
      [arr[start], arr[i]] = [arr[i], arr[start]]; // backtrack
    }
  }
  
  permute(cities.slice(1)); // Fix first city
  return minCost;
}

/*
Time complexity: O(n!) - factorial time
Even worse than exponential!
*/
```

## Factorial Time Complexity - O(n!)

Factorial complexity appears when generating all permutations or exploring all possible orderings.

### Permutation Generation

```javascript
function generatePermutations(arr) {
  if (arr.length <= 1) return [arr];
  
  const result = [];
  
  for (let i = 0; i < arr.length; i++) {
    const rest = [...arr.slice(0, i), ...arr.slice(i + 1)];
    const perms = generatePermutations(rest);
    
    for (let perm of perms) {
      result.push([arr[i], ...perm]);
    }
  }
  
  return result;
}

/*
Analysis:
- n choices for first position
- (n-1) choices for second position
- ...
- 1 choice for last position
- Total: n × (n-1) × ... × 1 = n!

For n=10: 3,628,800 permutations!
*/
```

### When Factorial Complexity Is Unavoidable

```javascript
// Brute force solution to NP-complete problems
function hamiltonianPath(graph) {
  const vertices = Object.keys(graph);
  const n = vertices.length;
  
  function hasPath(path) {
    for (let i = 0; i < path.length - 1; i++) {
      if (!graph[path[i]].includes(path[i + 1])) {
        return false;
      }
    }
    return true;
  }
  
  // Try all possible permutations
  const permutations = generatePermutations(vertices);
  
  for (let perm of permutations) {
    if (hasPath(perm)) return perm;
  }
  
  return null; // No Hamiltonian path exists
}

// Time: O(n! × n) - checking each permutation takes O(n)
```

## Amortized Analysis

Amortized analysis considers the **average performance** over a sequence of operations, not just worst-case single operations.

### Dynamic Array (ArrayList) Analysis

```javascript
class DynamicArray {
  constructor() {
    this.data = new Array(1);
    this.size = 0;
    this.capacity = 1;
  }
  
  push(item) {
    if (this.size === this.capacity) {
      this.resize();                    // Expensive: O(n)
    }
    
    this.data[this.size] = item;        // Cheap: O(1)
    this.size++;
  }
  
  resize() {
    const newCapacity = this.capacity * 2;
    const newData = new Array(newCapacity);
    
    for (let i = 0; i < this.size; i++) {
      newData[i] = this.data[i];        // Copy all elements: O(n)
    }
    
    this.data = newData;
    this.capacity = newCapacity;
  }
}

/*
Single operation analysis:
- Normal push: O(1)
- Push with resize: O(n)

Amortized analysis:
- Resize happens at: 1, 2, 4, 8, 16, 32, ... elements
- Cost sequence: 1, 2, 1, 4, 1, 1, 1, 8, ...
- Total cost for n pushes: n + (1 + 2 + 4 + 8 + ... + n) < 3n
- Amortized cost per push: O(1)
*/
```

### Hash Table with Chaining

```javascript
class HashTable {
  constructor(initialSize = 8) {
    this.buckets = new Array(initialSize).fill(null).map(() => []);
    this.size = 0;
    this.capacity = initialSize;
  }
  
  hash(key) {
    let hash = 0;
    for (let char of key) {
      hash = (hash * 31 + char.charCodeAt(0)) % this.capacity;
    }
    return hash;
  }
  
  set(key, value) {
    const index = this.hash(key);
    const bucket = this.buckets[index];
    
    // Check if key exists
    for (let i = 0; i < bucket.length; i++) {
      if (bucket[i][0] === key) {
        bucket[i][1] = value;
        return;
      }
    }
    
    // Add new key-value pair
    bucket.push([key, value]);
    this.size++;
    
    // Resize if load factor > 0.75
    if (this.size > this.capacity * 0.75) {
      this.resize();
    }
  }
  
  resize() {
    const oldBuckets = this.buckets;
    this.capacity *= 2;
    this.buckets = new Array(this.capacity).fill(null).map(() => []);
    this.size = 0;
    
    // Rehash all elements
    for (let bucket of oldBuckets) {
      for (let [key, value] of bucket) {
        this.set(key, value);           // O(n) total work
      }
    }
  }
}

/*
Amortized analysis:
- Normal set: O(1) average
- Set with resize: O(n)
- Resize frequency: every n/2 operations (load factor 0.75)
- Amortized cost: O(1) per operation
*/
```

## Advanced Recursive Complexities

### Tree Recursion with Memoization

```javascript
// Without memoization: O(2^n)
function longestIncreasingSubsequence(arr, index = 0, prev = -Infinity) {
  if (index === arr.length) return 0;
  
  // Choice 1: Skip current element
  let skip = longestIncreasingSubsequence(arr, index + 1, prev);
  
  // Choice 2: Include current element (if valid)
  let include = 0;
  if (arr[index] > prev) {
    include = 1 + longestIncreasingSubsequence(arr, index + 1, arr[index]);
  }
  
  return Math.max(skip, include);
}

// With memoization: O(n²)
function longestIncreasingSubsequenceMemo(arr) {
  const memo = new Map();
  
  function helper(index, prevValue) {
    if (index === arr.length) return 0;
    
    const key = `${index}-${prevValue}`;
    if (memo.has(key)) return memo.get(key);
    
    let skip = helper(index + 1, prevValue);
    let include = 0;
    
    if (arr[index] > prevValue) {
      include = 1 + helper(index + 1, arr[index]);
    }
    
    const result = Math.max(skip, include);
    memo.set(key, result);
    return result;
  }
  
  return helper(0, -Infinity);
}

/*
Memoization transforms:
- Time: O(2^n) → O(n²)
- Space: O(n) → O(n²)
*/
```

## Logarithmic Factors in Complex Algorithms

### O(n log n) with Different Log Bases

```javascript
// Merge sort: log₂(n) levels
function mergeSort(arr) {
  if (arr.length <= 1) return arr;
  
  const mid = Math.floor(arr.length / 2);
  const left = mergeSort(arr.slice(0, mid));
  const right = mergeSort(arr.slice(mid));
  
  return merge(left, right);
}

// Ternary merge sort: log₃(n) levels
function ternaryMergeSort(arr) {
  if (arr.length <= 1) return arr;
  
  const third1 = Math.floor(arr.length / 3);
  const third2 = Math.floor(2 * arr.length / 3);
  
  const part1 = ternaryMergeSort(arr.slice(0, third1));
  const part2 = ternaryMergeSort(arr.slice(third1, third2));
  const part3 = ternaryMergeSort(arr.slice(third2));
  
  return mergeThree(part1, part2, part3);
}

/*
Both are O(n log n), but:
- Binary: log₂(n) levels
- Ternary: log₃(n) levels

log₃(n) < log₂(n), so ternary has fewer levels
But merging 3 arrays is more complex than merging 2
In practice, binary merge sort is usually faster
*/
```

## Analyzing Complex Data Structures

### Skip List Operations

```javascript
class SkipListNode {
  constructor(value, level) {
    this.value = value;
    this.forward = new Array(level + 1).fill(null);
  }
}

class SkipList {
  constructor(maxLevel = 16) {
    this.maxLevel = maxLevel;
    this.header = new SkipListNode(-Infinity, maxLevel);
    this.level = 0;
  }
  
  randomLevel() {
    let level = 0;
    while (Math.random() < 0.5 && level < this.maxLevel) {
      level++;
    }
    return level;
  }
  
  search(target) {
    let current = this.header;
    
    // Start from highest level, work down
    for (let i = this.level; i >= 0; i--) {
      while (current.forward[i] && current.forward[i].value < target) {
        current = current.forward[i];
      }
    }
    
    current = current.forward[0];
    return current && current.value === target ? current : null;
  }
}

/*
Skip list analysis:
- Expected height: O(log n)
- Search time: O(log n) expected
- Worst case: O(n) if all elements at same level
- Space: O(n) expected, O(n log n) worst case

Probabilistic data structure with expected logarithmic performance
*/
```

## When to Accept High Complexity

### NP-Complete Problems

```javascript
// Graph coloring - no known polynomial solution
function graphColoring(graph, numColors) {
  const vertices = Object.keys(graph);
  const coloring = {};
  
  function isValidColoring(vertex, color) {
    for (let neighbor of graph[vertex]) {
      if (coloring[neighbor] === color) {
        return false;
      }
    }
    return true;
  }
  
  function backtrack(vertexIndex) {
    if (vertexIndex === vertices.length) {
      return true; // All vertices colored
    }
    
    const vertex = vertices[vertexIndex];
    
    for (let color = 1; color <= numColors; color++) {
      if (isValidColoring(vertex, color)) {
        coloring[vertex] = color;
        
        if (backtrack(vertexIndex + 1)) {
          return true;
        }
        
        delete coloring[vertex]; // backtrack
      }
    }
    
    return false;
  }
  
  return backtrack(0) ? coloring : null;
}

/*
Time complexity: O(k^n) where k = numColors, n = vertices
This is exponential, but it's the best known general solution
For specific graph types, polynomial algorithms may exist
*/
```

### Approximation Algorithms

```javascript
// TSP approximation (2-approximation)
function tspApproximation(distances) {
  const n = distances.length;
  
  // 1. Find minimum spanning tree - O(n² log n)
  const mst = findMST(distances);
  
  // 2. DFS traversal of MST - O(n)
  const tour = dfsTraversal(mst, 0);
  
  // 3. Convert to Hamiltonian cycle - O(n)
  return makeHamiltonian(tour);
}

/*
Exact TSP: O(n!)
Approximation: O(n² log n)

Tradeoff: Get solution within 2× optimal in polynomial time
versus exponential time for exact solution
*/
```

## Key Takeaways

1. **Exponential algorithms** quickly become impractical but may be the only known solution
2. **Factorial complexity** appears in permutation/combination problems
3. **Amortized analysis** reveals true average performance over operation sequences
4. **Memoization** can transform exponential to polynomial complexity
5. **Probabilistic data structures** offer expected good performance
6. **Approximation algorithms** provide polynomial solutions to exponential problems
7. **Know when to accept high complexity** - some problems are inherently hard

---

Ready to learn systematic analysis methods? Next, we'll explore advanced techniques like the master theorem and recursion trees.

### What's Next?

**Part 6: Practical Analysis Methods** - Master theorem, recursion trees, loop analysis techniques, and advanced mathematical tools for algorithm analysis.
